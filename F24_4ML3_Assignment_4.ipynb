{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak-hannou/compsci-4ml3/blob/main/F24_4ML3_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MZ69kOAE-LG"
      },
      "source": [
        "# Assignment 4: Application of Neural Networks for Image Processing\n",
        "\n",
        "In this assignment, you will complete three main tasks to deepen your understanding of neural networks, specifically using Convolutional Neural Networks (CNNs) for image processing:\n",
        "\n",
        "1. **Image Classification with CNN (30 points)**  \n",
        "   Create an image classifier using PyTorch, building and training a CNN model to classify images accurately.\n",
        "\n",
        "2. **Image Denoising with CNN (45 points)**  \n",
        "   Develop a denoising model using PyTorch, leveraging a CNN to remove noise from images and enhance visual quality.\n",
        "\n",
        "3. **Kaggle Competition (25 + 20 points)**  \n",
        "   Participate in a Kaggle competition where you will apply your skills in image classification on a challenging dataset.\n",
        "\n",
        "---\n",
        "\n",
        "# Submission Guidelines\n",
        "\n",
        "### Your submission on A2L should include **five files** in total:\n",
        "\n",
        "1. **Report** (`report.pdf`): Document your results and answer all assignment-related questions in this PDF.\n",
        "\n",
        "2. **Code** (`F24-4ML3-Assignment 4.ipynb`): Submit your code in a Jupyter Notebook file, maintaining the original notebook structure provided.\n",
        "\n",
        "3. **Kaggle Code**: Provide a separate file with the code specifically used for the Kaggle competition.\n",
        "\n",
        "4. **Kaggle Report** (`kaggle.pdf`): Write a concise report explaining your approach and model used in the competition.\n",
        "\n",
        "5. **Submission File** (`submission.csv`): Refer to the Kaggle Competition section for details on generating and uploading this file to A2L.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Total Points**: 120 (with an additional 20 bonus points available for Kaggle competition)\n",
        "\n",
        "**Submission Deadline**: December 2, 2024 11:59PM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtlpcfSz80XH"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import torch  # Core PyTorch library for tensor operations\n",
        "from torchvision import datasets, transforms  # Datasets and transformations for computer vision\n",
        "import torch.nn as nn  # Neural network components\n",
        "import torch.optim as optim  # Optimization algorithms\n",
        "import numpy as np  # Numerical operations\n",
        "import matplotlib.pyplot as plt  # Plotting\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, Subset  # Data handling utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm-gUxWzI6DN"
      },
      "source": [
        "# SVHN Dataset\n",
        "\n",
        "In this assignment, you will work with the **Street View House Numbers (SVHN) dataset** to develop a denoising algorithm and a classification task. The SVHN dataset consists of over **600,000** color images of house numbers collected from Google Street View images. Each image is a 32x32 pixel RGB image capturing digits (0-9) in real-world scenarios. The dataset can be found at [this link](http://ufldl.stanford.edu/housenumbers/).\n",
        "\n",
        "For this assignment, you will use:\n",
        "\n",
        "- **Training set**: 73,257 images\n",
        "- **Testing set**: 26,032 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeGPybKkJ9TO"
      },
      "outputs": [],
      "source": [
        "# Define transformations for the dataset\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "testset = datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "# Set batch size as a parameter\n",
        "batch_size = 64\n",
        "\n",
        "# Function to create data loaders with a specified batch size\n",
        "def get_dataloader(dataset, batch_size, shuffle):\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "trainloader = get_dataloader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = get_dataloader(testset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVkyiOcMjV7R"
      },
      "source": [
        "# Visualization of SVHN dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class labels for the SVHN dataset\n",
        "classes = [str(i) for i in range(10)]\n",
        "\n",
        "# Function to display a grid of images with specified rows, columns, and class labels\n",
        "def show_images_grid(dataloader, rows, cols):\n",
        "    # Get a batch of training images and labels\n",
        "    dataiter = iter(dataloader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
        "    idx = 0\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            if idx < len(images):\n",
        "                npimg = images[idx].numpy()\n",
        "                axes[i, j].imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "                axes[i, j].set_title(f'Class: {classes[labels[idx]]}')\n",
        "                axes[i, j].axis('off')\n",
        "                idx += 1\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1NEHoJwFrv3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2x5 grid of images from trainloader\n",
        "show_images_grid(trainloader, rows=2, cols=5)"
      ],
      "metadata": {
        "id": "DowQrDwor0xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `del` keyword deletes variables from memory, freeing up space. This is useful in large projects, especially deep learning, where datasets and data loaders use significant memory. Removing these variables ensures available memory for later code and helps avoid conflicts with similar names.\n"
      ],
      "metadata": {
        "id": "yHmf23nI7iOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del trainset, testset, trainloader, testloader, transform, batch_size, get_dataloader"
      ],
      "metadata": {
        "id": "gB8QF5Bb64iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiICDe1EvQi9"
      },
      "source": [
        "# <font color=\"red\">Task 1: SVHN Image Classification Using a Convolutional Neural Network (CNN) (30 points) </font>\n",
        "\n",
        "In this task, you will complete the implementation of a CNN model and use it to classify images from the SVHN dataset. Your goal is to build an accurate model that can recognize and classify house number digits in real-world images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWowxbzawUMP"
      },
      "source": [
        "When available, a GPU can accelerate neural network training with parallel computations, ideal for large datasets and complex models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9e4EbGvwHmu"
      },
      "outputs": [],
      "source": [
        "# Set up device for training (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper-Parameters:"
      ],
      "metadata": {
        "id": "lfflzVmG75PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64           # Batch size for data loading\n",
        "learning_rate = 0.05      # Learning rate for optimizer\n",
        "num_epochs = 20           # Number of training epochs"
      ],
      "metadata": {
        "id": "m_bgWMct74Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "FZXFM2-c_sGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for SVHN dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "])\n",
        "\n",
        "# Load training and test datasets with transformations\n",
        "train_dataset = datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_dataset = datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "# Create data loaders with specified batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "bQ9Ioatf6x5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhHQ-h7MX-EV"
      },
      "source": [
        "## **A (15 points)** Build the CNN Model\n",
        "\n",
        "\n",
        "A convolutional layer can be implemented in pytorch like\n",
        "\n",
        "```\n",
        "nn.Conv2d(in_channels=, out_channels=, kernel_size=, padding=, stride=).\n",
        "```\n",
        "\n",
        "Complete the CNN model implementation with the following architecture:\n",
        "\n",
        "1. **Convolutional Layers**:\n",
        "   - Three convolutional layers with:\n",
        "     - `kernel_size=3`, `stride=1`, `padding=1`\n",
        "     - Output channels:\n",
        "       - First layer: 32 channels\n",
        "       - Second layer: 64 channels\n",
        "       - Third layer: 128 channels\n",
        "   - Each convolutional layer is followed by:\n",
        "     - Batch normalization to stabilize and speed up training\n",
        "     - ReLU activation for non-linearity\n",
        "     - Max pooling (`kernel_size=2`, `stride=2`) to reduce spatial dimensions\n",
        "\n",
        "2. **Fully Connected Layers**:\n",
        "   - Flatten the output from the convolutional layers.\n",
        "   - First fully connected layer with 128 units and ReLU activation.\n",
        "   - Final fully connected layer with 10 units for classification (one for each class in SVHN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL2NlAcNsevJ"
      },
      "outputs": [],
      "source": [
        "class SVHNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SVHNClassifier, self).__init__()\n",
        "\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bXI9ZfPoxN_"
      },
      "source": [
        "## **B (15 points)** Train the network\n",
        "In the part, we are going to train the SVHN_CNN model to classify SVHN dataset.\n",
        "\n",
        "1. Finish implementing train and test functions.\n",
        "2. Include last epoch results for train/test loss and train/test accuracy in your report\n",
        "3. Plot the train/test losses and train/test accuracies using the plot_metrics function.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model and move to device\n",
        "model = SVHNClassifier().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # CrossEntropy includes softmax\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "t6rvQia08zSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to evaluate model performance\n",
        "def evaluate(model, data_loader, criterion):\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    with torch.no_grad():  # No gradient calculation for evaluation\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n",
        "\n",
        "\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "    return accuracy, avg_loss"
      ],
      "metadata": {
        "id": "GgOnIh8p9HpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    # Evaluate on train and test sets after each epoch\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1:02d}/{num_epochs:02d} - Train Loss: {train_loss:.6f}, Train Acc: {train_accuracy:.2f}%')\n",
        "    print(f'            - Test Loss: {test_loss:.6f}, Test Acc: {test_accuracy:.2f}%')\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)"
      ],
      "metadata": {
        "id": "lgq-IONg9geU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(train_metrics, test_metrics, metric_name):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    epochs = np.arange(len(train_metrics))\n",
        "\n",
        "    plt.plot(epochs, train_metrics, label=f'Train {metric_name}', color='blue')\n",
        "    plt.plot(epochs, test_metrics, label=f'Test {metric_name}', color='red')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title(f'{metric_name} over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DvsNLf6TkuKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss\n",
        "plot_metrics(train_losses, test_losses, 'Loss')"
      ],
      "metadata": {
        "id": "fn7UkttYHA4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy\n",
        "plot_metrics(train_accuracies, test_accuracies, 'Accuracy')"
      ],
      "metadata": {
        "id": "YV5fI0QaHD-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb0eAplR3lqu"
      },
      "source": [
        "# <font color=\"red\">Task 2: SVHN Denoising with Convolution Neural Network (CNN) (45 points) </font>\n",
        "Convolutional Neural Network (CNN) have also been quite successful in the field of image processing. In this part, you are asked to finish the implementation of the CNN model and use the model to denoise images from SVHN.\n",
        "\n",
        "The objective of tasks in the assignment is to train a network that, given a noisy image, recovers the original image. Therefore, each training point consists of the input (noisy image) and the expected output (true image).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we remove these variables ensures available memory for later code and helps avoid conflicts with similar names."
      ],
      "metadata": {
        "id": "CF86MWduFSCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del device, batch_size, learning_rate, num_epochs,\\\n",
        "     train_dataset, test_dataset, train_loader, test_loader, transform,\\\n",
        "     SVHNClassifier, model, criterion, optimizer, evaluate,\\\n",
        "     train_losses, test_losses, train_accuracies, test_accuracies, show_images_grid, classes"
      ],
      "metadata": {
        "id": "CsAijt_XFWWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up device for training (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "flvbSD1cYwZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Noisy dataset"
      ],
      "metadata": {
        "id": "MDw3RNEzsiFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Defining a Custom Noise Transformation\n",
        "First, we define a custom transformation that applies noise to each image by randomly dropping pixels. This transformation will be used to generate a noisy version of every image in the dataset."
      ],
      "metadata": {
        "id": "NeAfK0vOts9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom transformation to add noise by dropping pixels with a given probability for each channel independently\n",
        "class AddNoiseTransform:\n",
        "    def __init__(self, drop_prob=0.1):\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def __call__(self, img):\n",
        "        channel_mask = (torch.rand(img.shape) > self.drop_prob).float()\n",
        "        noisy_img = img * channel_mask\n",
        "        return noisy_img"
      ],
      "metadata": {
        "id": "Z1bFRklWuIxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Creating a Dataset of Paired Images: Original and Noisy\n",
        "We define a dataset that pairs each original image with a corresponding noisy image. This dataset is structured so that each data sample includes both the clean image (as the label) and the noisified version (as the feature). We then create PyTorch dataloaders where each element contains a pair of original and noisy images."
      ],
      "metadata": {
        "id": "Me5pHteAGAHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PairDataset class that returns a pair of images: (original, noisy)\n",
        "class PairDataset(Dataset):\n",
        "    def __init__(self, dataset_origin, dataset_noisy):\n",
        "        assert len(dataset_origin) == len(dataset_noisy), \"Datasets must be of the same length\"\n",
        "        self.dataset_origin = dataset_origin\n",
        "        self.dataset_noisy = dataset_noisy\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        clean_img, _ = self.dataset_origin[index]\n",
        "        noisy_img, _ = self.dataset_noisy[index]\n",
        "        return clean_img, noisy_img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_origin)"
      ],
      "metadata": {
        "id": "ayq12fKxxg21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create paired dataset for specific classes\n",
        "def create_paired_dataloader(classes, num_samples=1500, batch_size=64, drop_prob=0.5, split='train'):\n",
        "    \"\"\"\n",
        "    Creates a DataLoader for a paired dataset with noisy and clean images from specified classes.\n",
        "\n",
        "    Parameters:\n",
        "    - classes (list): List of class labels to include (e.g., [0, 1, 2, 3, 4] or [5, 6, 7, 8, 9]).\n",
        "    - num_samples (int): Number of samples to use from the filtered classes.\n",
        "    - batch_size (int): Batch size for the DataLoader.\n",
        "    - drop_prob (float): Drop probability for AddNoiseTransform.\n",
        "    - split (str): Dataset split to load ('train' or 'test').\n",
        "\n",
        "    Returns:\n",
        "    - DataLoader: A DataLoader for the paired dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define transformations\n",
        "    transform_clean = transforms.ToTensor()\n",
        "    transform_noisy = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        AddNoiseTransform(drop_prob=drop_prob)\n",
        "    ])\n",
        "\n",
        "    # Load the specified dataset split\n",
        "    dataset_clean_full = datasets.SVHN(root='./data', split=split, download=True, transform=transform_clean)\n",
        "    dataset_noisy_full = datasets.SVHN(root='./data', split=split, download=True, transform=transform_noisy)\n",
        "\n",
        "    # Filter to include only samples with specified classes\n",
        "    indices = [i for i, (_, label) in enumerate(dataset_clean_full) if label in classes]\n",
        "\n",
        "    # Take only the first `num_samples` samples after filtering\n",
        "    subset_indices = indices[:num_samples]\n",
        "\n",
        "    # Create clean and noisy subsets\n",
        "    dataset_clean = Subset(dataset_clean_full, subset_indices)\n",
        "    dataset_noisy = Subset(dataset_noisy_full, subset_indices)\n",
        "\n",
        "    # Create the paired dataset\n",
        "    paired_dataset = PairDataset(dataset_clean, dataset_noisy)\n",
        "\n",
        "    # DataLoader for paired dataset\n",
        "    paired_dataloader = DataLoader(paired_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return paired_dataloader"
      ],
      "metadata": {
        "id": "MBYKKlk_1r-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ytXCfKY7ZFG"
      },
      "source": [
        "## **Task A (10 points): Implementing a CNN for Image Denoising**\n",
        "\n",
        "In this task, you will implement a Convolutional Neural Network (CNN) to map noisy images to their original, clean versions. This architecture consists of two convolutional layers.\n",
        "\n",
        "### **Architecture Details**\n",
        "\n",
        "1. **First Convolutional Layer**\n",
        "   - **Setup**: `kernel_size=3`, `padding=1`, `stride=1` to maintain image dimensions.\n",
        "   - **Input**: 32x32x3 images.\n",
        "   - **Output**: Feature maps of size 32x32x30.\n",
        "   - **Activation**: Apply ReLU for non-linearity.\n",
        "\n",
        "2. **Second Convolutional Layer**\n",
        "   - **Setup**: Same kernel size, padding, and stride as above.\n",
        "   - **Output**: 32x32x3 to match the original image dimensions.\n",
        "   - **Activation**: Sigmoid to constrain values between 0 and 1.\n",
        "\n",
        "3. **Hyperparameters**\n",
        "   - `input_channels=3`, `output_channels=3`, `feature_maps=30`.\n",
        "\n",
        "### **Implementation Requirements**\n",
        "\n",
        "Using these guidelines, implement the CNN model in PyTorch with `torch.nn.Conv2d` for the layers, and `torch.nn.ReLU` and `torch.nn.Sigmoid` for activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_L9u1C-4nIo"
      },
      "outputs": [],
      "source": [
        "class ImageDenoisingCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageDenoisingCNN, self).__init__()\n",
        "\n",
        "\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv41pQYDFZVj"
      },
      "source": [
        "To understand the model’s complexity, we can calculate the total number of trainable parameters in ImageDenoisingCNN. Each parameter contributes to the model's ability to learn patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mESWDv-zFfMT"
      },
      "outputs": [],
      "source": [
        "model = ImageDenoisingCNN()\n",
        "\n",
        "# Calculate and print the number of trainable parameters\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('Total number of trainable parameters in ImageDenoisingCNN:', num_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvXxyL___CrN"
      },
      "source": [
        "## **Task B (20 points)**: Denoising SVHN Images\n",
        "This task involves building and evaluating a model that can remove noise from SVHN images in the first 5 classes (0 through 4). The model is trained and tested on a dataset of noisy images paired with their clean counterparts, using only 1,500 samples per class.\n",
        "\n",
        "**Objectives**:\n",
        "1. Complete the training function: This function should return the average training and test losses for each epoch.\n",
        "2. Complete the testing function: This function should compute the average test loss across all batches.\n",
        "3. Denoise SVHN Images: Train the model to denoise images from the first 5 classes.\n",
        "\n",
        "Include the last epoch train/test values and last epoch sample images in your report."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a single row of images with specified columns\n",
        "def show_images_grid2(images, title, cols):\n",
        "    fig, axes = plt.subplots(1, cols, figsize=(cols * 2, 2))\n",
        "    if cols == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx in range(cols):\n",
        "        if idx < len(images):\n",
        "            img = images[idx].numpy().transpose((1, 2, 0))\n",
        "            axes[idx].imshow(img)\n",
        "            axes[idx].set_title(title)\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "06Rz8te50cE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, test_loader, model, epochs, loss_function, optimizer, device='cuda'):\n",
        "    \"\"\"\n",
        "    Train the model on the training dataset and evaluate it on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - train_loader: DataLoader for the training set\n",
        "    - test_loader: DataLoader for the test set\n",
        "    - model: Neural network model to train\n",
        "    - epochs: Number of training epochs\n",
        "    - loss_function: Loss function for training\n",
        "    - optimizer: Optimizer for updating model weights\n",
        "    - device: Device to use for training ('cuda' or 'cpu')\n",
        "\n",
        "    Returns:\n",
        "    - train_loss_epochs: List of average training losses per epoch\n",
        "    - test_loss_epochs: List of average test losses per epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # Move model to the specified device\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    train_loss_epochs = []\n",
        "    test_loss_epochs = []\n",
        "\n",
        "    # Loop over the dataset for a specified number of epochs\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        train_loss_batches = []\n",
        "\n",
        "        # Loop over batches in the training data\n",
        "\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n",
        "\n",
        "            # Display sample results every 5 epochs, at the last batch of each epoch\n",
        "            if epoch % 5 == 0 and batch_idx == len(train_loader) - 1:\n",
        "                show_images_grid2(clean_images[:5].detach().cpu(), title= \"Clean\", cols=5)\n",
        "                show_images_grid2(noisy_images[:5].detach().cpu(), title= \"Noisy\", cols=5)\n",
        "                show_images_grid2(denoised_images[:5].detach().cpu(), title= \"Denoised\", cols=5)\n",
        "\n",
        "\n",
        "        # Calculate average training loss for the epoch\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "        # Evaluate model on the test set and calculate test loss\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "        # Print losses for the current epoch\n",
        "        print(f'Epoch {epoch+1:02d}/{epochs:02d} - Train Loss: {train_loss_epoch:.6f}, Test Loss: {test_loss_epoch:.6f}')\n",
        "\n",
        "    return train_loss_epochs, test_loss_epochs"
      ],
      "metadata": {
        "id": "VLYIAvC4Ryt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qwiRBGj6f0j"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader, model, loss_function, device='cuda'):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset and return the average loss.\n",
        "    \"\"\"\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for testing\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    return np.mean(test_losses)  # Return average loss over the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOdQHvId6gXr"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.05\n",
        "batch_size = 64\n",
        "drop_rate = 0.3\n",
        "num_samples = 1500\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "\n",
        "########################\n",
        "########################\n",
        "#### YOUR CODE HERE ####\n",
        "########################\n",
        "########################\n",
        "\n",
        "\n",
        "# Load data\n",
        "\n",
        "########################\n",
        "########################\n",
        "#### YOUR CODE HERE ####\n",
        "########################\n",
        "########################\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train_loss_epochs, test_loss_epochs = train(paired_trainloader_first_five, paired_testloader_first_five,\\\n",
        "                                            model, num_epochs, criterion, optimizer, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFGYWd77-e_o"
      },
      "source": [
        "## **Task C (5 points): Plotting Training and Testing Losses Over Epochs**\n",
        "\n",
        "To visualize the learning process of your model, plot the training and testing losses over each epoch. This allows you to evaluate model performance over time and helps identify potential issues, such as overfitting or underfitting.\n",
        "\n",
        "Include this plot in your report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAiPTlOY-yCz"
      },
      "outputs": [],
      "source": [
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9NHmFlD_ZvJ"
      },
      "source": [
        "## **Task D (10 points): Denoising Last 5 Classes, Reporting Loss, and Visualization**\n",
        "\n",
        "Use your model to denoise images from classes 5-9 of the SVHN dataset. Report the test loss and visualize clean, noisy, and denoised images side by side. Include these results in your report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z53JphDj_8DD"
      },
      "outputs": [],
      "source": [
        "# Load test data for classes 5-9 with 1,500 samples per class\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "print(f'Number of batches in paired_testloader_last_five: {len(paired_testloader_last_five)}')\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate model on the last 5 classes test set and report loss\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr837mj3AMf9"
      },
      "outputs": [],
      "source": [
        "# Visualize clean, noisy, and denoised images on last 5 classes\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "# Display clean, noisy, and denoised images\n",
        "show_images_grid2(clean_images[:5].detach(), title=\"Clean\", cols=5)\n",
        "show_images_grid2(noisy_images[:5].detach(), title=\"Noisy\", cols=5)\n",
        "show_images_grid2(denoised_images, title=\"Denoised\", cols=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\"> Task 3: Kaggle Competition (25 + 20 Bonus Points) </font>\n",
        "\n",
        "For this task, you will participate in a Kaggle competition. Follow the steps below to maximize your performance and gain additional points:\n",
        "\n",
        "1. **Account Setup**: Create a Kaggle account if you don’t already have one, and log in. Make sure to include your Kaggle username in both your report and code submission for verification purposes.\n",
        "\n",
        "2. **Competition Details**: Access the competition at the link provided below and thoroughly read the description and requirements. Implement your solution in a separate file (not in this notebook) and aim to achieve the highest score possible on the leaderboard.\n",
        "\n",
        "   - **[Kaggle Competition Link](<https://www.kaggle.com/t/37714339d17855022339af848ed11e96>)**\n",
        "\n",
        "3. **Submission on A2L**: Ensure your A2L submission includes:\n",
        "   - **Final Code**: Upload your final code file used for the Kaggle competition.\n",
        "   - **Report** (`kaggle.pdf`): Provide a detailed report explaining your model and approach, along with the code used in your last Kaggle submission.\n",
        "     - Start the report with your final accuracy score.\n",
        "     - Clearly mention your Kaggle username for verification.\n",
        "   - **Submission File** (`submission.csv`): Upload the final `submission.csv` file used in the competition as a record of your performance.\n",
        "\n",
        "4. **Bonus Points**: Additional points will be awarded to the top-performing students on the competition leaderboard.\n"
      ],
      "metadata": {
        "id": "ZSqyl3gi4POS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}