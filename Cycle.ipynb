{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "SbrUI1waCgh-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import pickle\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import imageio\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "image_size = 32\n",
        "conv_dim = 64\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "train_iters = 400 #40000\n",
        "use_reconst_loss = True\n",
        "log_step = 10\n",
        "sample_step = 5 #500\n",
        "sample_path = './samples'"
      ],
      "metadata": {
        "id": "TAi_FCkEnDGY"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "KlP3a1fMr-WN"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader():\n",
        "    \"\"\"Builds and returns Dataloader for MNIST and SVHN dataset.\"\"\"\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    svhn = datasets.SVHN(root='./svhn', download=True, transform=transform, split='train')\n",
        "    mnist = datasets.MNIST(root='./mnist', download=True, transform=transform, train=True)\n",
        "\n",
        "    svhn_test = datasets.SVHN(root='./svhn', download=True, transform=transform, split='test')\n",
        "    mnist_test = datasets.MNIST(root='./mnist', download=True, transform=transform, train=False)\n",
        "\n",
        "    svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)\n",
        "\n",
        "    mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=2)\n",
        "\n",
        "\n",
        "    svhn_test_loader = torch.utils.data.DataLoader(dataset=svhn_test,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=False,\n",
        "                                              num_workers=2)\n",
        "\n",
        "    mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=False,\n",
        "                                               num_workers=2)\n",
        "\n",
        "    return svhn_loader, mnist_loader, svhn_test_loader, mnist_test_loader"
      ],
      "metadata": {
        "id": "G7iBIylMgA3W"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svhn_loader, mnist_loader, svhn_test_loader, mnist_test_loader = get_loader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgV48DdLsxm8",
        "outputId": "64b08434-4cb3-481d-bedd-91fa2c8287f7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./svhn/train_32x32.mat\n",
            "Using downloaded and verified file: ./svhn/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "Dcf0hCx5gge8"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class G12(nn.Module):\n",
        "    \"\"\"Generator for transfering from mnist to svhn\"\"\"\n",
        "    def __init__(self, conv_dim=64, svhn_input=None):\n",
        "        super(G12, self).__init__()\n",
        "\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(1, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "\n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "\n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1 = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out_2 = F.leaky_relu(self.conv2(out_1), 0.05)    # (?, 128, 8, 8)\n",
        "\n",
        "        out_3 = F.leaky_relu(self.conv3(out_2), 0.05)    # ( \" )\n",
        "        out_4 = F.leaky_relu(self.conv4(out_3), 0.05)    # ( \" )\n",
        "\n",
        "        out_5 = F.leaky_relu(self.deconv1(out_4), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out_5))              # (?, 3, 32, 32)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "s6klYFPAgpFS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class G21(nn.Module):\n",
        "    \"\"\"Generator for transfering from svhn to mnist\"\"\"\n",
        "    def __init__(self,  conv_dim=64, svhn_input=None):\n",
        "        super(G21, self).__init__()\n",
        "\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "\n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "\n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1 = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out_2 = F.leaky_relu(self.conv2(out_1), 0.05)    # (?, 128, 8, 8)\n",
        "\n",
        "        out_3 = F.leaky_relu(self.conv3(out_2), 0.05)    # ( \" )\n",
        "        out_4 = F.leaky_relu(self.conv4(out_3), 0.05)    # ( \" )\n",
        "\n",
        "        out_5 = F.leaky_relu(self.deconv1(out_4), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out_5))              # (?, 1, 32, 32)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "doRaFOyCgsa9"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class D1(nn.Module):\n",
        "    \"\"\"Discriminator for mnist.\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(D1, self).__init__()\n",
        "        self.conv1 = conv(1, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        self.fc = conv(conv_dim*4, 1, 4, 1, 0, False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ],
      "metadata": {
        "id": "BT8WQAADgxQN"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class D2(nn.Module):\n",
        "    \"\"\"Discriminator for svhn.\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(D2, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        self.fc = conv(conv_dim*4, 1, 4, 1, 0, False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ],
      "metadata": {
        "id": "RRNbNlTHg2FV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "    def __init__(self, svhn_loader, mnist_loader):\n",
        "        self.svhn_loader = svhn_loader\n",
        "        self.mnist_loader = mnist_loader\n",
        "        self.g12 = None\n",
        "        self.g21 = None\n",
        "        self.d1 = None\n",
        "        self.d2 = None\n",
        "        self.g_optimizer = None\n",
        "        self.d_optimizer = None\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Builds a generator and a discriminator.\"\"\"\n",
        "        self.g12 = G12(conv_dim=conv_dim)\n",
        "        self.g21 = G21(conv_dim=conv_dim)\n",
        "        self.d1 = D1(conv_dim=conv_dim)\n",
        "        self.d2 = D2(conv_dim=conv_dim)\n",
        "\n",
        "        g_params = list(self.g12.parameters()) + list(self.g21.parameters())\n",
        "        d_params = list(self.d1.parameters()) + list(self.d2.parameters())\n",
        "\n",
        "        self.g_optimizer = optim.Adam(g_params, lr, [beta1, beta2])\n",
        "        self.d_optimizer = optim.Adam(d_params, lr, [beta1, beta2])\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.g12.cuda()\n",
        "            self.g21.cuda()\n",
        "            self.d1.cuda()\n",
        "            self.d2.cuda()\n",
        "\n",
        "    def merge_images(self, sources, targets, k=10):\n",
        "        _, _, h, w = sources.shape\n",
        "        row = int(np.sqrt(batch_size))\n",
        "        merged = np.zeros([3, row*h, row*w*2])\n",
        "        for idx, (s, t) in enumerate(zip(sources, targets)):\n",
        "            i = idx // row\n",
        "            j = idx % row\n",
        "            merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "            merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "        return merged.transpose(1, 2, 0)\n",
        "\n",
        "    def to_var(self, x):\n",
        "        \"\"\"Converts numpy to variable.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cuda()\n",
        "        return Variable(x)\n",
        "\n",
        "    def to_data(self, x):\n",
        "        \"\"\"Converts variable to numpy.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cpu()\n",
        "        return x.data.numpy()\n",
        "\n",
        "    def reset_grad(self):\n",
        "        \"\"\"Zeros the gradient buffers.\"\"\"\n",
        "        self.g_optimizer.zero_grad()\n",
        "        self.d_optimizer.zero_grad()\n",
        "\n",
        "    def as_np(self, data):\n",
        "        return data.cpu().data.numpy()\n",
        "\n",
        "    def train(self, svhn_test_loader, mnist_test_loader):\n",
        "        svhn_iter = iter(self.svhn_loader)\n",
        "        mnist_iter = iter(self.mnist_loader)\n",
        "        iter_per_epoch = min(len(svhn_iter), len(mnist_iter)) -1\n",
        "\n",
        "        # fixed mnist and svhn for sampling\n",
        "        svhn_test_iter = iter(svhn_test_loader)\n",
        "        mnist_test_iter = iter(mnist_test_loader)\n",
        "        fixed_svhn = next(svhn_test_iter)\n",
        "        fixed_mnist = next(mnist_test_iter)\n",
        "\n",
        "        fixed_svhn = fixed_svhn[0].to(device,dtype=torch.float)\n",
        "        fixed_mnist = fixed_mnist[0].to(device,dtype=torch.float)\n",
        "\n",
        "        for step in range(train_iters+1):\n",
        "            # reset data_iter for each epoch\n",
        "            if (step+1) % iter_per_epoch == 0:\n",
        "                mnist_iter = iter(self.mnist_loader)\n",
        "                svhn_iter = iter(self.svhn_loader)\n",
        "\n",
        "            # load svhn and mnist dataset\n",
        "            svhn, s_labels = next(svhn_iter)\n",
        "            svhn, s_labels = self.to_var(svhn), self.to_var(s_labels).long().squeeze()\n",
        "            mnist, m_labels = next(mnist_iter)\n",
        "            mnist, m_labels = self.to_var(mnist), self.to_var(m_labels)\n",
        "\n",
        "            #============ train D ============#\n",
        "\n",
        "            # train with real images\n",
        "            self.reset_grad()\n",
        "            out = self.d1(mnist)\n",
        "            d1_loss = torch.mean((out-1)**2)\n",
        "\n",
        "            out = self.d2(svhn)\n",
        "            d2_loss = torch.mean((out-1)**2)\n",
        "\n",
        "            d_mnist_loss = d1_loss\n",
        "            d_svhn_loss = d2_loss\n",
        "            d_real_loss = d1_loss + d2_loss\n",
        "            d_real_loss.backward()\n",
        "            self.d_optimizer.step()\n",
        "\n",
        "            # train with fake images\n",
        "            self.reset_grad()\n",
        "            fake_svhn = self.g12(mnist)\n",
        "            out = self.d2(fake_svhn)\n",
        "            d2_loss = torch.mean(out**2)\n",
        "\n",
        "            fake_mnist = self.g21(svhn)\n",
        "            out = self.d1(fake_mnist)\n",
        "            d1_loss = torch.mean(out**2)\n",
        "\n",
        "            d_fake_loss = d1_loss + d2_loss\n",
        "            d_fake_loss.backward()\n",
        "            self.d_optimizer.step()\n",
        "\n",
        "            #============ train G ============#\n",
        "\n",
        "            # train mnist-svhn-mnist cycle\n",
        "            self.reset_grad()\n",
        "            fake_svhn = self.g12(mnist)\n",
        "            out_svhn = self.d2(fake_svhn)\n",
        "            reconst_mnist = self.g21(fake_svhn)\n",
        "\n",
        "            gen_loss_A = torch.mean((out_svhn-1)**2)\n",
        "            g_loss = gen_loss_A\n",
        "\n",
        "            if use_reconst_loss:\n",
        "                reconst_loss_A = torch.mean((mnist - reconst_mnist) ** 2)\n",
        "                g_loss += reconst_loss_A\n",
        "\n",
        "            g_loss.backward()\n",
        "            self.g_optimizer.step()\n",
        "\n",
        "            # train svhn-mnist-svhn cycle\n",
        "            self.reset_grad()\n",
        "            fake_mnist  = self.g21(svhn)\n",
        "            out_mnist = self.d1(fake_mnist)\n",
        "            reconst_svhn = self.g12(fake_mnist)\n",
        "\n",
        "            gen_loss_B = torch.mean((out_mnist - 1) ** 2)\n",
        "            g_loss = gen_loss_B\n",
        "\n",
        "            if use_reconst_loss:\n",
        "                reconst_loss_B = torch.mean((svhn - reconst_svhn) ** 2)\n",
        "                g_loss += reconst_loss_B\n",
        "\n",
        "            g_loss.backward()\n",
        "            self.g_optimizer.step()\n",
        "\n",
        "            # print the log info\n",
        "            if (step+1) % log_step == 0:\n",
        "\n",
        "                print('Step [%d/%d], d_real_loss: %.4f, d_mnist_loss: %.4f, d_svhn_loss: %.4f, '\n",
        "                      'd_fake_loss: %.4f, gen_loss_A: %.4f, gen_loss_B: %.4f,'\n",
        "                      %(step+1, train_iters, d_real_loss.item(), d_mnist_loss.item(),\n",
        "                        d_svhn_loss.item(), d_fake_loss.item(), gen_loss_A.item(),gen_loss_B.item()))\n",
        "\n",
        "                if use_reconst_loss:\n",
        "                    print ('reconst_loss_A: %.4f, recons_loss_B: %.4f, ' %\n",
        "                           (reconst_loss_A.item(), reconst_loss_B.item()))\n",
        "\n",
        "\n",
        "            # save the sampled images\n",
        "            if (step+1) % sample_step == 0:\n",
        "                fake_svhn = self.g12(fixed_mnist)\n",
        "                fake_mnist = self.g21(fixed_svhn)\n",
        "\n",
        "                mnist, fake_mnist = self.to_data(fixed_mnist), self.to_data(fake_mnist)\n",
        "                svhn , fake_svhn = self.to_data(fixed_svhn), self.to_data(fake_svhn)\n",
        "\n",
        "                merged = self.merge_images(mnist, fake_svhn)\n",
        "                merged = (merged * 255).astype('uint8')\n",
        "                path = os.path.join(sample_path, 'sample-%d-m-s.png' %(step+1))\n",
        "                imageio.imwrite(path, merged)\n",
        "                print ('saved %s' %path)\n",
        "\n",
        "                merged = self.merge_images(svhn, fake_mnist)\n",
        "                merged = (merged * 255).astype('uint8')\n",
        "                path = os.path.join(sample_path, 'sample-%d-s-m.png' %(step+1))\n",
        "                imageio.imwrite(path, merged)\n",
        "                print ('saved %s' %path)"
      ],
      "metadata": {
        "id": "bZirOuRejglW"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create directories if not exist\n",
        "if not os.path.exists(sample_path):\n",
        "      os.makedirs(sample_path)\n"
      ],
      "metadata": {
        "id": "CuYk8QMpnYni"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver = Solver(svhn_loader, mnist_loader)\n",
        "solver.train(svhn_test_loader, mnist_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxwytE2ypfyJ",
        "outputId": "8af0fa1d-8a0d-4197-f879-07e131d7bc5d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [10/4000], d_real_loss: 1.2894, d_mnist_loss: 0.2837, d_svhn_loss: 1.0057, d_fake_loss: 3.0810, gen_loss_A: 9.6788, gen_loss_B: 1.3250,\n",
            "reconst_loss_A: 0.9470, recons_loss_B: 0.4832, \n",
            "Step [20/4000], d_real_loss: 0.4207, d_mnist_loss: 0.2436, d_svhn_loss: 0.1770, d_fake_loss: 2.6705, gen_loss_A: 6.4560, gen_loss_B: 2.0398,\n",
            "reconst_loss_A: 0.7151, recons_loss_B: 0.4402, \n",
            "Step [30/4000], d_real_loss: 0.3593, d_mnist_loss: 0.2838, d_svhn_loss: 0.0755, d_fake_loss: 2.8598, gen_loss_A: 4.8810, gen_loss_B: 2.2877,\n",
            "reconst_loss_A: 0.5394, recons_loss_B: 0.4561, \n",
            "Step [40/4000], d_real_loss: 0.1860, d_mnist_loss: 0.1036, d_svhn_loss: 0.0823, d_fake_loss: 1.4992, gen_loss_A: 2.8970, gen_loss_B: 2.8059,\n",
            "reconst_loss_A: 0.3781, recons_loss_B: 0.4634, \n",
            "Step [50/4000], d_real_loss: 0.1857, d_mnist_loss: 0.0691, d_svhn_loss: 0.1166, d_fake_loss: 1.5544, gen_loss_A: 6.0815, gen_loss_B: 1.1481,\n",
            "reconst_loss_A: 0.3254, recons_loss_B: 0.4682, \n",
            "saved ./samples/sample-50-m-s.png\n",
            "saved ./samples/sample-50-s-m.png\n",
            "Step [60/4000], d_real_loss: 0.3197, d_mnist_loss: 0.1623, d_svhn_loss: 0.1575, d_fake_loss: 0.8286, gen_loss_A: 3.2665, gen_loss_B: 2.5562,\n",
            "reconst_loss_A: 0.3448, recons_loss_B: 0.4826, \n",
            "Step [70/4000], d_real_loss: 0.1326, d_mnist_loss: 0.0758, d_svhn_loss: 0.0569, d_fake_loss: 0.1714, gen_loss_A: 1.9052, gen_loss_B: 1.6241,\n",
            "reconst_loss_A: 0.3165, recons_loss_B: 0.4712, \n",
            "Step [80/4000], d_real_loss: 0.3262, d_mnist_loss: 0.1322, d_svhn_loss: 0.1940, d_fake_loss: 0.1669, gen_loss_A: 1.3222, gen_loss_B: 1.7860,\n",
            "reconst_loss_A: 0.2831, recons_loss_B: 0.3456, \n",
            "Step [90/4000], d_real_loss: 0.1542, d_mnist_loss: 0.0949, d_svhn_loss: 0.0593, d_fake_loss: 0.3076, gen_loss_A: 1.6328, gen_loss_B: 2.1394,\n",
            "reconst_loss_A: 0.2900, recons_loss_B: 0.3938, \n",
            "Step [100/4000], d_real_loss: 0.1303, d_mnist_loss: 0.0657, d_svhn_loss: 0.0646, d_fake_loss: 0.1894, gen_loss_A: 1.6883, gen_loss_B: 0.9306,\n",
            "reconst_loss_A: 0.2502, recons_loss_B: 0.2439, \n",
            "saved ./samples/sample-100-m-s.png\n",
            "saved ./samples/sample-100-s-m.png\n",
            "Step [110/4000], d_real_loss: 0.3599, d_mnist_loss: 0.0855, d_svhn_loss: 0.2744, d_fake_loss: 0.3477, gen_loss_A: 1.4944, gen_loss_B: 2.0386,\n",
            "reconst_loss_A: 0.2652, recons_loss_B: 0.4484, \n",
            "Step [120/4000], d_real_loss: 0.4980, d_mnist_loss: 0.1219, d_svhn_loss: 0.3761, d_fake_loss: 0.3734, gen_loss_A: 1.4221, gen_loss_B: 1.5846,\n",
            "reconst_loss_A: 0.2172, recons_loss_B: 0.3353, \n",
            "Step [130/4000], d_real_loss: 0.3655, d_mnist_loss: 0.2406, d_svhn_loss: 0.1249, d_fake_loss: 0.3336, gen_loss_A: 1.3949, gen_loss_B: 1.3149,\n",
            "reconst_loss_A: 0.2063, recons_loss_B: 0.3061, \n",
            "Step [140/4000], d_real_loss: 0.1489, d_mnist_loss: 0.0419, d_svhn_loss: 0.1071, d_fake_loss: 0.1368, gen_loss_A: 1.5248, gen_loss_B: 1.3395,\n",
            "reconst_loss_A: 0.2345, recons_loss_B: 0.2029, \n",
            "Step [150/4000], d_real_loss: 0.5046, d_mnist_loss: 0.0782, d_svhn_loss: 0.4264, d_fake_loss: 0.3770, gen_loss_A: 1.3680, gen_loss_B: 1.7076,\n",
            "reconst_loss_A: 0.2416, recons_loss_B: 0.2362, \n",
            "saved ./samples/sample-150-m-s.png\n",
            "saved ./samples/sample-150-s-m.png\n",
            "Step [160/4000], d_real_loss: 0.4824, d_mnist_loss: 0.2877, d_svhn_loss: 0.1946, d_fake_loss: 0.5227, gen_loss_A: 2.0166, gen_loss_B: 1.5469,\n",
            "reconst_loss_A: 0.2414, recons_loss_B: 0.2677, \n",
            "Step [170/4000], d_real_loss: 0.6351, d_mnist_loss: 0.3880, d_svhn_loss: 0.2471, d_fake_loss: 0.7856, gen_loss_A: 1.7105, gen_loss_B: 1.9214,\n",
            "reconst_loss_A: 0.1692, recons_loss_B: 0.2509, \n",
            "Step [180/4000], d_real_loss: 0.4968, d_mnist_loss: 0.1935, d_svhn_loss: 0.3033, d_fake_loss: 0.2114, gen_loss_A: 1.3044, gen_loss_B: 1.4664,\n",
            "reconst_loss_A: 0.2004, recons_loss_B: 0.2697, \n",
            "Step [190/4000], d_real_loss: 0.2860, d_mnist_loss: 0.0917, d_svhn_loss: 0.1942, d_fake_loss: 0.2261, gen_loss_A: 1.7194, gen_loss_B: 1.8247,\n",
            "reconst_loss_A: 0.2000, recons_loss_B: 0.2407, \n",
            "Step [200/4000], d_real_loss: 0.3481, d_mnist_loss: 0.0646, d_svhn_loss: 0.2836, d_fake_loss: 0.1033, gen_loss_A: 1.1688, gen_loss_B: 1.3687,\n",
            "reconst_loss_A: 0.2085, recons_loss_B: 0.2359, \n",
            "saved ./samples/sample-200-m-s.png\n",
            "saved ./samples/sample-200-s-m.png\n",
            "Step [210/4000], d_real_loss: 0.4537, d_mnist_loss: 0.3121, d_svhn_loss: 0.1417, d_fake_loss: 0.3240, gen_loss_A: 1.6901, gen_loss_B: 1.5391,\n",
            "reconst_loss_A: 0.1894, recons_loss_B: 0.2354, \n",
            "Step [220/4000], d_real_loss: 0.1525, d_mnist_loss: 0.0473, d_svhn_loss: 0.1052, d_fake_loss: 0.6834, gen_loss_A: 1.9634, gen_loss_B: 1.4428,\n",
            "reconst_loss_A: 0.1966, recons_loss_B: 0.1809, \n",
            "Step [230/4000], d_real_loss: 0.1979, d_mnist_loss: 0.0337, d_svhn_loss: 0.1641, d_fake_loss: 0.1976, gen_loss_A: 1.4087, gen_loss_B: 2.1248,\n",
            "reconst_loss_A: 0.1862, recons_loss_B: 0.2057, \n",
            "Step [240/4000], d_real_loss: 0.2532, d_mnist_loss: 0.1624, d_svhn_loss: 0.0908, d_fake_loss: 0.0719, gen_loss_A: 1.3531, gen_loss_B: 1.1508,\n",
            "reconst_loss_A: 0.1875, recons_loss_B: 0.2259, \n",
            "Step [250/4000], d_real_loss: 0.1891, d_mnist_loss: 0.0868, d_svhn_loss: 0.1023, d_fake_loss: 0.1660, gen_loss_A: 1.3553, gen_loss_B: 1.1372,\n",
            "reconst_loss_A: 0.1690, recons_loss_B: 0.2557, \n",
            "saved ./samples/sample-250-m-s.png\n",
            "saved ./samples/sample-250-s-m.png\n",
            "Step [260/4000], d_real_loss: 0.2545, d_mnist_loss: 0.1735, d_svhn_loss: 0.0810, d_fake_loss: 0.5462, gen_loss_A: 1.4251, gen_loss_B: 1.9983,\n",
            "reconst_loss_A: 0.2043, recons_loss_B: 0.2533, \n",
            "Step [270/4000], d_real_loss: 0.4161, d_mnist_loss: 0.0354, d_svhn_loss: 0.3806, d_fake_loss: 0.1832, gen_loss_A: 1.4359, gen_loss_B: 1.8306,\n",
            "reconst_loss_A: 0.2052, recons_loss_B: 0.1967, \n",
            "Step [280/4000], d_real_loss: 0.1816, d_mnist_loss: 0.1351, d_svhn_loss: 0.0465, d_fake_loss: 0.3693, gen_loss_A: 2.1246, gen_loss_B: 1.4643,\n",
            "reconst_loss_A: 0.2074, recons_loss_B: 0.1977, \n",
            "Step [290/4000], d_real_loss: 0.1500, d_mnist_loss: 0.0458, d_svhn_loss: 0.1042, d_fake_loss: 0.2684, gen_loss_A: 2.3303, gen_loss_B: 1.4643,\n",
            "reconst_loss_A: 0.2321, recons_loss_B: 0.1853, \n",
            "Step [300/4000], d_real_loss: 0.1362, d_mnist_loss: 0.0714, d_svhn_loss: 0.0648, d_fake_loss: 0.0765, gen_loss_A: 1.5838, gen_loss_B: 1.6104,\n",
            "reconst_loss_A: 0.2252, recons_loss_B: 0.1755, \n",
            "saved ./samples/sample-300-m-s.png\n",
            "saved ./samples/sample-300-s-m.png\n",
            "Step [310/4000], d_real_loss: 0.3205, d_mnist_loss: 0.2222, d_svhn_loss: 0.0983, d_fake_loss: 0.5259, gen_loss_A: 1.3291, gen_loss_B: 2.1460,\n",
            "reconst_loss_A: 0.2109, recons_loss_B: 0.2668, \n",
            "Step [320/4000], d_real_loss: 0.1836, d_mnist_loss: 0.0818, d_svhn_loss: 0.1018, d_fake_loss: 0.0852, gen_loss_A: 1.4420, gen_loss_B: 1.1780,\n",
            "reconst_loss_A: 0.2260, recons_loss_B: 0.3085, \n",
            "Step [330/4000], d_real_loss: 0.4310, d_mnist_loss: 0.1390, d_svhn_loss: 0.2920, d_fake_loss: 0.1426, gen_loss_A: 1.3169, gen_loss_B: 1.4031,\n",
            "reconst_loss_A: 0.1611, recons_loss_B: 0.2220, \n",
            "Step [340/4000], d_real_loss: 0.1670, d_mnist_loss: 0.1020, d_svhn_loss: 0.0650, d_fake_loss: 0.1177, gen_loss_A: 1.5036, gen_loss_B: 1.4953,\n",
            "reconst_loss_A: 0.1820, recons_loss_B: 0.1943, \n",
            "Step [350/4000], d_real_loss: 0.1937, d_mnist_loss: 0.0988, d_svhn_loss: 0.0949, d_fake_loss: 0.2152, gen_loss_A: 1.5088, gen_loss_B: 1.4105,\n",
            "reconst_loss_A: 0.2393, recons_loss_B: 0.1817, \n",
            "saved ./samples/sample-350-m-s.png\n",
            "saved ./samples/sample-350-s-m.png\n",
            "Step [360/4000], d_real_loss: 0.1561, d_mnist_loss: 0.1081, d_svhn_loss: 0.0480, d_fake_loss: 0.1414, gen_loss_A: 1.2251, gen_loss_B: 1.4766,\n",
            "reconst_loss_A: 0.1707, recons_loss_B: 0.1943, \n",
            "Step [370/4000], d_real_loss: 0.2193, d_mnist_loss: 0.0763, d_svhn_loss: 0.1430, d_fake_loss: 0.1787, gen_loss_A: 1.6271, gen_loss_B: 1.4787,\n",
            "reconst_loss_A: 0.2262, recons_loss_B: 0.1670, \n",
            "Step [380/4000], d_real_loss: 0.2264, d_mnist_loss: 0.0670, d_svhn_loss: 0.1595, d_fake_loss: 0.4815, gen_loss_A: 2.0636, gen_loss_B: 1.4252,\n",
            "reconst_loss_A: 0.1789, recons_loss_B: 0.2440, \n",
            "Step [390/4000], d_real_loss: 0.1509, d_mnist_loss: 0.1100, d_svhn_loss: 0.0409, d_fake_loss: 0.1256, gen_loss_A: 1.3169, gen_loss_B: 1.3770,\n",
            "reconst_loss_A: 0.2149, recons_loss_B: 0.1935, \n",
            "Step [400/4000], d_real_loss: 0.4569, d_mnist_loss: 0.1833, d_svhn_loss: 0.2736, d_fake_loss: 0.2637, gen_loss_A: 1.3425, gen_loss_B: 1.4427,\n",
            "reconst_loss_A: 0.1752, recons_loss_B: 0.1551, \n",
            "saved ./samples/sample-400-m-s.png\n",
            "saved ./samples/sample-400-s-m.png\n",
            "Step [410/4000], d_real_loss: 0.1590, d_mnist_loss: 0.0770, d_svhn_loss: 0.0820, d_fake_loss: 0.5538, gen_loss_A: 2.0644, gen_loss_B: 1.7127,\n",
            "reconst_loss_A: 0.1613, recons_loss_B: 0.1936, \n",
            "Step [420/4000], d_real_loss: 0.2938, d_mnist_loss: 0.0734, d_svhn_loss: 0.2203, d_fake_loss: 0.5325, gen_loss_A: 1.6057, gen_loss_B: 2.6134,\n",
            "reconst_loss_A: 0.1784, recons_loss_B: 0.2015, \n",
            "Step [430/4000], d_real_loss: 0.2596, d_mnist_loss: 0.2202, d_svhn_loss: 0.0394, d_fake_loss: 0.3495, gen_loss_A: 1.8035, gen_loss_B: 1.4044,\n",
            "reconst_loss_A: 0.1858, recons_loss_B: 0.2268, \n",
            "Step [440/4000], d_real_loss: 0.3312, d_mnist_loss: 0.2745, d_svhn_loss: 0.0567, d_fake_loss: 0.2070, gen_loss_A: 1.3643, gen_loss_B: 1.2787,\n",
            "reconst_loss_A: 0.1897, recons_loss_B: 0.1731, \n",
            "Step [450/4000], d_real_loss: 0.2338, d_mnist_loss: 0.0811, d_svhn_loss: 0.1527, d_fake_loss: 0.5203, gen_loss_A: 2.0668, gen_loss_B: 1.3355,\n",
            "reconst_loss_A: 0.2004, recons_loss_B: 0.2117, \n",
            "saved ./samples/sample-450-m-s.png\n",
            "saved ./samples/sample-450-s-m.png\n",
            "Step [460/4000], d_real_loss: 0.1783, d_mnist_loss: 0.0474, d_svhn_loss: 0.1309, d_fake_loss: 0.2387, gen_loss_A: 1.4010, gen_loss_B: 1.9404,\n",
            "reconst_loss_A: 0.2053, recons_loss_B: 0.2446, \n",
            "Step [470/4000], d_real_loss: 0.2167, d_mnist_loss: 0.0700, d_svhn_loss: 0.1468, d_fake_loss: 0.1332, gen_loss_A: 1.1420, gen_loss_B: 1.4686,\n",
            "reconst_loss_A: 0.1948, recons_loss_B: 0.1560, \n",
            "Step [480/4000], d_real_loss: 0.2003, d_mnist_loss: 0.0589, d_svhn_loss: 0.1414, d_fake_loss: 0.1693, gen_loss_A: 1.4077, gen_loss_B: 1.3612,\n",
            "reconst_loss_A: 0.1824, recons_loss_B: 0.1824, \n",
            "Step [490/4000], d_real_loss: 0.8973, d_mnist_loss: 0.7470, d_svhn_loss: 0.1503, d_fake_loss: 0.3031, gen_loss_A: 1.4413, gen_loss_B: 1.1778,\n",
            "reconst_loss_A: 0.1721, recons_loss_B: 0.1491, \n",
            "Step [500/4000], d_real_loss: 0.4090, d_mnist_loss: 0.2855, d_svhn_loss: 0.1234, d_fake_loss: 0.3306, gen_loss_A: 1.5323, gen_loss_B: 1.5661,\n",
            "reconst_loss_A: 0.2195, recons_loss_B: 0.2566, \n",
            "saved ./samples/sample-500-m-s.png\n",
            "saved ./samples/sample-500-s-m.png\n",
            "Step [510/4000], d_real_loss: 0.2630, d_mnist_loss: 0.1756, d_svhn_loss: 0.0874, d_fake_loss: 0.1041, gen_loss_A: 1.0759, gen_loss_B: 0.8153,\n",
            "reconst_loss_A: 0.1908, recons_loss_B: 0.1362, \n",
            "Step [520/4000], d_real_loss: 0.2349, d_mnist_loss: 0.1204, d_svhn_loss: 0.1145, d_fake_loss: 0.3108, gen_loss_A: 1.5511, gen_loss_B: 1.3486,\n",
            "reconst_loss_A: 0.1927, recons_loss_B: 0.1733, \n",
            "Step [530/4000], d_real_loss: 0.4553, d_mnist_loss: 0.1054, d_svhn_loss: 0.3499, d_fake_loss: 0.1900, gen_loss_A: 1.0162, gen_loss_B: 1.7200,\n",
            "reconst_loss_A: 0.1661, recons_loss_B: 0.1425, \n",
            "Step [540/4000], d_real_loss: 0.7124, d_mnist_loss: 0.4000, d_svhn_loss: 0.3124, d_fake_loss: 0.6039, gen_loss_A: 1.8474, gen_loss_B: 0.9822,\n",
            "reconst_loss_A: 0.1918, recons_loss_B: 0.1452, \n",
            "Step [550/4000], d_real_loss: 0.1914, d_mnist_loss: 0.0836, d_svhn_loss: 0.1078, d_fake_loss: 0.2556, gen_loss_A: 1.6283, gen_loss_B: 1.1458,\n",
            "reconst_loss_A: 0.1754, recons_loss_B: 0.1198, \n",
            "saved ./samples/sample-550-m-s.png\n",
            "saved ./samples/sample-550-s-m.png\n",
            "Step [560/4000], d_real_loss: 0.1392, d_mnist_loss: 0.0229, d_svhn_loss: 0.1163, d_fake_loss: 0.1919, gen_loss_A: 1.9405, gen_loss_B: 1.1963,\n",
            "reconst_loss_A: 0.2331, recons_loss_B: 0.1236, \n",
            "Step [570/4000], d_real_loss: 0.5204, d_mnist_loss: 0.3655, d_svhn_loss: 0.1550, d_fake_loss: 0.2590, gen_loss_A: 1.5774, gen_loss_B: 1.2359,\n",
            "reconst_loss_A: 0.2476, recons_loss_B: 0.2013, \n",
            "Step [580/4000], d_real_loss: 0.1247, d_mnist_loss: 0.0519, d_svhn_loss: 0.0727, d_fake_loss: 0.2619, gen_loss_A: 1.1539, gen_loss_B: 1.6188,\n",
            "reconst_loss_A: 0.1858, recons_loss_B: 0.1529, \n",
            "Step [590/4000], d_real_loss: 0.3626, d_mnist_loss: 0.1012, d_svhn_loss: 0.2614, d_fake_loss: 0.3747, gen_loss_A: 1.6200, gen_loss_B: 1.5581,\n",
            "reconst_loss_A: 0.1800, recons_loss_B: 0.1852, \n",
            "Step [600/4000], d_real_loss: 0.2439, d_mnist_loss: 0.0807, d_svhn_loss: 0.1632, d_fake_loss: 0.0967, gen_loss_A: 1.0287, gen_loss_B: 1.4585,\n",
            "reconst_loss_A: 0.1569, recons_loss_B: 0.1912, \n",
            "saved ./samples/sample-600-m-s.png\n",
            "saved ./samples/sample-600-s-m.png\n",
            "Step [610/4000], d_real_loss: 0.3078, d_mnist_loss: 0.0415, d_svhn_loss: 0.2663, d_fake_loss: 0.1854, gen_loss_A: 1.2075, gen_loss_B: 1.7037,\n",
            "reconst_loss_A: 0.2043, recons_loss_B: 0.1020, \n",
            "Step [620/4000], d_real_loss: 0.2474, d_mnist_loss: 0.0627, d_svhn_loss: 0.1847, d_fake_loss: 0.1842, gen_loss_A: 1.5614, gen_loss_B: 1.1234,\n",
            "reconst_loss_A: 0.2051, recons_loss_B: 0.1139, \n",
            "Step [630/4000], d_real_loss: 0.6817, d_mnist_loss: 0.1264, d_svhn_loss: 0.5553, d_fake_loss: 0.2585, gen_loss_A: 1.4904, gen_loss_B: 0.8654,\n",
            "reconst_loss_A: 0.2075, recons_loss_B: 0.2723, \n",
            "Step [640/4000], d_real_loss: 0.4149, d_mnist_loss: 0.2466, d_svhn_loss: 0.1683, d_fake_loss: 0.4877, gen_loss_A: 2.2630, gen_loss_B: 1.1800,\n",
            "reconst_loss_A: 0.2600, recons_loss_B: 0.2512, \n",
            "Step [650/4000], d_real_loss: 0.1709, d_mnist_loss: 0.0351, d_svhn_loss: 0.1358, d_fake_loss: 0.1022, gen_loss_A: 1.0799, gen_loss_B: 1.2427,\n",
            "reconst_loss_A: 0.2130, recons_loss_B: 0.1507, \n",
            "saved ./samples/sample-650-m-s.png\n",
            "saved ./samples/sample-650-s-m.png\n",
            "Step [660/4000], d_real_loss: 0.3274, d_mnist_loss: 0.1969, d_svhn_loss: 0.1305, d_fake_loss: 0.2248, gen_loss_A: 1.3876, gen_loss_B: 1.1108,\n",
            "reconst_loss_A: 0.1718, recons_loss_B: 0.1531, \n",
            "Step [670/4000], d_real_loss: 0.1371, d_mnist_loss: 0.0327, d_svhn_loss: 0.1044, d_fake_loss: 0.1265, gen_loss_A: 1.5493, gen_loss_B: 1.4743,\n",
            "reconst_loss_A: 0.1559, recons_loss_B: 0.1812, \n",
            "Step [680/4000], d_real_loss: 0.2164, d_mnist_loss: 0.1266, d_svhn_loss: 0.0898, d_fake_loss: 0.1746, gen_loss_A: 1.2227, gen_loss_B: 1.5313,\n",
            "reconst_loss_A: 0.1871, recons_loss_B: 0.1912, \n",
            "Step [690/4000], d_real_loss: 0.4374, d_mnist_loss: 0.1034, d_svhn_loss: 0.3340, d_fake_loss: 0.2804, gen_loss_A: 1.3835, gen_loss_B: 1.6106,\n",
            "reconst_loss_A: 0.1937, recons_loss_B: 0.2479, \n",
            "Step [700/4000], d_real_loss: 0.1157, d_mnist_loss: 0.0507, d_svhn_loss: 0.0650, d_fake_loss: 0.1373, gen_loss_A: 1.2871, gen_loss_B: 1.4539,\n",
            "reconst_loss_A: 0.1729, recons_loss_B: 0.2242, \n",
            "saved ./samples/sample-700-m-s.png\n",
            "saved ./samples/sample-700-s-m.png\n",
            "Step [710/4000], d_real_loss: 0.3417, d_mnist_loss: 0.0309, d_svhn_loss: 0.3107, d_fake_loss: 0.1211, gen_loss_A: 0.9833, gen_loss_B: 1.5350,\n",
            "reconst_loss_A: 0.1762, recons_loss_B: 0.1737, \n",
            "Step [720/4000], d_real_loss: 0.1507, d_mnist_loss: 0.0770, d_svhn_loss: 0.0736, d_fake_loss: 0.0532, gen_loss_A: 1.2987, gen_loss_B: 0.8895,\n",
            "reconst_loss_A: 0.1973, recons_loss_B: 0.2155, \n",
            "Step [730/4000], d_real_loss: 0.1405, d_mnist_loss: 0.0454, d_svhn_loss: 0.0951, d_fake_loss: 0.1481, gen_loss_A: 1.2806, gen_loss_B: 0.8551,\n",
            "reconst_loss_A: 0.1445, recons_loss_B: 0.1719, \n",
            "Step [740/4000], d_real_loss: 0.0700, d_mnist_loss: 0.0457, d_svhn_loss: 0.0243, d_fake_loss: 0.1723, gen_loss_A: 1.6589, gen_loss_B: 1.6028,\n",
            "reconst_loss_A: 0.1863, recons_loss_B: 0.2816, \n",
            "Step [750/4000], d_real_loss: 0.1560, d_mnist_loss: 0.1141, d_svhn_loss: 0.0419, d_fake_loss: 0.0685, gen_loss_A: 1.3819, gen_loss_B: 1.3550,\n",
            "reconst_loss_A: 0.1737, recons_loss_B: 0.1828, \n",
            "saved ./samples/sample-750-m-s.png\n",
            "saved ./samples/sample-750-s-m.png\n",
            "Step [760/4000], d_real_loss: 0.2275, d_mnist_loss: 0.1128, d_svhn_loss: 0.1147, d_fake_loss: 0.1051, gen_loss_A: 1.2576, gen_loss_B: 1.3644,\n",
            "reconst_loss_A: 0.2217, recons_loss_B: 0.1994, \n",
            "Step [770/4000], d_real_loss: 0.2211, d_mnist_loss: 0.1037, d_svhn_loss: 0.1175, d_fake_loss: 0.1922, gen_loss_A: 1.5070, gen_loss_B: 0.9728,\n",
            "reconst_loss_A: 0.1544, recons_loss_B: 0.2172, \n",
            "Step [780/4000], d_real_loss: 0.3027, d_mnist_loss: 0.2505, d_svhn_loss: 0.0522, d_fake_loss: 0.2272, gen_loss_A: 1.2799, gen_loss_B: 1.8744,\n",
            "reconst_loss_A: 0.1781, recons_loss_B: 0.1981, \n",
            "Step [790/4000], d_real_loss: 0.1018, d_mnist_loss: 0.0325, d_svhn_loss: 0.0693, d_fake_loss: 1.1132, gen_loss_A: 2.9888, gen_loss_B: 1.9843,\n",
            "reconst_loss_A: 0.1628, recons_loss_B: 0.1637, \n",
            "Step [800/4000], d_real_loss: 0.2853, d_mnist_loss: 0.0783, d_svhn_loss: 0.2070, d_fake_loss: 0.1631, gen_loss_A: 0.9990, gen_loss_B: 1.3811,\n",
            "reconst_loss_A: 0.2076, recons_loss_B: 0.1364, \n",
            "saved ./samples/sample-800-m-s.png\n",
            "saved ./samples/sample-800-s-m.png\n",
            "Step [810/4000], d_real_loss: 0.2383, d_mnist_loss: 0.1466, d_svhn_loss: 0.0917, d_fake_loss: 0.1349, gen_loss_A: 1.5570, gen_loss_B: 1.8404,\n",
            "reconst_loss_A: 0.1613, recons_loss_B: 0.1632, \n",
            "Step [820/4000], d_real_loss: 0.2517, d_mnist_loss: 0.0956, d_svhn_loss: 0.1561, d_fake_loss: 0.3017, gen_loss_A: 2.2317, gen_loss_B: 1.4619,\n",
            "reconst_loss_A: 0.1767, recons_loss_B: 0.2453, \n",
            "Step [830/4000], d_real_loss: 0.1048, d_mnist_loss: 0.0665, d_svhn_loss: 0.0382, d_fake_loss: 0.1279, gen_loss_A: 1.4262, gen_loss_B: 1.2882,\n",
            "reconst_loss_A: 0.2155, recons_loss_B: 0.1912, \n",
            "Step [840/4000], d_real_loss: 0.7257, d_mnist_loss: 0.0383, d_svhn_loss: 0.6874, d_fake_loss: 0.2904, gen_loss_A: 1.7850, gen_loss_B: 1.3920,\n",
            "reconst_loss_A: 0.1922, recons_loss_B: 0.2389, \n",
            "Step [850/4000], d_real_loss: 0.1121, d_mnist_loss: 0.0484, d_svhn_loss: 0.0637, d_fake_loss: 0.1623, gen_loss_A: 1.6977, gen_loss_B: 1.8393,\n",
            "reconst_loss_A: 0.1992, recons_loss_B: 0.2434, \n",
            "saved ./samples/sample-850-m-s.png\n",
            "saved ./samples/sample-850-s-m.png\n",
            "Step [860/4000], d_real_loss: 0.1624, d_mnist_loss: 0.1147, d_svhn_loss: 0.0477, d_fake_loss: 0.3090, gen_loss_A: 1.3284, gen_loss_B: 1.1854,\n",
            "reconst_loss_A: 0.2122, recons_loss_B: 0.1462, \n",
            "Step [870/4000], d_real_loss: 0.1126, d_mnist_loss: 0.0220, d_svhn_loss: 0.0906, d_fake_loss: 0.0372, gen_loss_A: 1.2990, gen_loss_B: 1.1833,\n",
            "reconst_loss_A: 0.1852, recons_loss_B: 0.1696, \n",
            "Step [880/4000], d_real_loss: 0.2184, d_mnist_loss: 0.1186, d_svhn_loss: 0.0998, d_fake_loss: 0.1079, gen_loss_A: 1.3164, gen_loss_B: 1.0835,\n",
            "reconst_loss_A: 0.1559, recons_loss_B: 0.2060, \n",
            "Step [890/4000], d_real_loss: 0.1121, d_mnist_loss: 0.0334, d_svhn_loss: 0.0787, d_fake_loss: 0.1221, gen_loss_A: 1.2449, gen_loss_B: 1.2748,\n",
            "reconst_loss_A: 0.1555, recons_loss_B: 0.1712, \n",
            "Step [900/4000], d_real_loss: 0.0688, d_mnist_loss: 0.0257, d_svhn_loss: 0.0431, d_fake_loss: 0.1101, gen_loss_A: 1.2602, gen_loss_B: 1.4213,\n",
            "reconst_loss_A: 0.1829, recons_loss_B: 0.1870, \n",
            "saved ./samples/sample-900-m-s.png\n",
            "saved ./samples/sample-900-s-m.png\n",
            "Step [910/4000], d_real_loss: 0.1888, d_mnist_loss: 0.0873, d_svhn_loss: 0.1016, d_fake_loss: 0.2474, gen_loss_A: 1.2796, gen_loss_B: 1.3115,\n",
            "reconst_loss_A: 0.1834, recons_loss_B: 0.1240, \n",
            "Step [920/4000], d_real_loss: 0.2069, d_mnist_loss: 0.1643, d_svhn_loss: 0.0426, d_fake_loss: 0.3096, gen_loss_A: 1.6574, gen_loss_B: 1.5161,\n",
            "reconst_loss_A: 0.1517, recons_loss_B: 0.1642, \n",
            "Step [930/4000], d_real_loss: 0.2249, d_mnist_loss: 0.1634, d_svhn_loss: 0.0615, d_fake_loss: 0.2554, gen_loss_A: 1.5372, gen_loss_B: 1.5847,\n",
            "reconst_loss_A: 0.1720, recons_loss_B: 0.2072, \n",
            "Step [940/4000], d_real_loss: 0.3294, d_mnist_loss: 0.1889, d_svhn_loss: 0.1405, d_fake_loss: 0.1126, gen_loss_A: 1.7108, gen_loss_B: 1.1041,\n",
            "reconst_loss_A: 0.1717, recons_loss_B: 0.2061, \n",
            "Step [950/4000], d_real_loss: 0.1814, d_mnist_loss: 0.1691, d_svhn_loss: 0.0123, d_fake_loss: 0.0574, gen_loss_A: 1.3045, gen_loss_B: 1.8897,\n",
            "reconst_loss_A: 0.1585, recons_loss_B: 0.2261, \n",
            "saved ./samples/sample-950-m-s.png\n",
            "saved ./samples/sample-950-s-m.png\n",
            "Step [960/4000], d_real_loss: 0.1857, d_mnist_loss: 0.0985, d_svhn_loss: 0.0872, d_fake_loss: 0.3477, gen_loss_A: 1.6038, gen_loss_B: 1.2946,\n",
            "reconst_loss_A: 0.1930, recons_loss_B: 0.1480, \n",
            "Step [970/4000], d_real_loss: 0.1433, d_mnist_loss: 0.0719, d_svhn_loss: 0.0715, d_fake_loss: 0.1451, gen_loss_A: 1.2818, gen_loss_B: 1.2909,\n",
            "reconst_loss_A: 0.1750, recons_loss_B: 0.2260, \n",
            "Step [980/4000], d_real_loss: 0.2227, d_mnist_loss: 0.0465, d_svhn_loss: 0.1762, d_fake_loss: 0.1722, gen_loss_A: 1.4127, gen_loss_B: 1.4425,\n",
            "reconst_loss_A: 0.1657, recons_loss_B: 0.1632, \n",
            "Step [990/4000], d_real_loss: 0.0683, d_mnist_loss: 0.0255, d_svhn_loss: 0.0427, d_fake_loss: 0.7130, gen_loss_A: 2.8640, gen_loss_B: 1.3676,\n",
            "reconst_loss_A: 0.1439, recons_loss_B: 0.1962, \n",
            "Step [1000/4000], d_real_loss: 0.1979, d_mnist_loss: 0.0323, d_svhn_loss: 0.1657, d_fake_loss: 0.3648, gen_loss_A: 1.1621, gen_loss_B: 1.6729,\n",
            "reconst_loss_A: 0.2102, recons_loss_B: 0.2684, \n",
            "saved ./samples/sample-1000-m-s.png\n",
            "saved ./samples/sample-1000-s-m.png\n",
            "Step [1010/4000], d_real_loss: 0.2478, d_mnist_loss: 0.0956, d_svhn_loss: 0.1521, d_fake_loss: 0.0756, gen_loss_A: 1.3402, gen_loss_B: 1.5138,\n",
            "reconst_loss_A: 0.1428, recons_loss_B: 0.2013, \n",
            "Step [1020/4000], d_real_loss: 0.1444, d_mnist_loss: 0.0178, d_svhn_loss: 0.1266, d_fake_loss: 0.1836, gen_loss_A: 0.9261, gen_loss_B: 1.6128,\n",
            "reconst_loss_A: 0.1152, recons_loss_B: 0.2510, \n",
            "Step [1030/4000], d_real_loss: 0.1917, d_mnist_loss: 0.0818, d_svhn_loss: 0.1099, d_fake_loss: 0.2236, gen_loss_A: 1.2716, gen_loss_B: 1.5829,\n",
            "reconst_loss_A: 0.1867, recons_loss_B: 0.1539, \n",
            "Step [1040/4000], d_real_loss: 0.6944, d_mnist_loss: 0.0879, d_svhn_loss: 0.6065, d_fake_loss: 0.3650, gen_loss_A: 0.9623, gen_loss_B: 1.2462,\n",
            "reconst_loss_A: 0.2110, recons_loss_B: 0.1645, \n",
            "Step [1050/4000], d_real_loss: 0.3742, d_mnist_loss: 0.1983, d_svhn_loss: 0.1758, d_fake_loss: 0.0738, gen_loss_A: 1.0556, gen_loss_B: 0.9954,\n",
            "reconst_loss_A: 0.2074, recons_loss_B: 0.1977, \n",
            "saved ./samples/sample-1050-m-s.png\n",
            "saved ./samples/sample-1050-s-m.png\n",
            "Step [1060/4000], d_real_loss: 0.1103, d_mnist_loss: 0.0284, d_svhn_loss: 0.0819, d_fake_loss: 0.1062, gen_loss_A: 1.3008, gen_loss_B: 0.8980,\n",
            "reconst_loss_A: 0.1724, recons_loss_B: 0.1431, \n",
            "Step [1070/4000], d_real_loss: 0.2683, d_mnist_loss: 0.0970, d_svhn_loss: 0.1713, d_fake_loss: 0.1116, gen_loss_A: 1.2298, gen_loss_B: 1.1759,\n",
            "reconst_loss_A: 0.1894, recons_loss_B: 0.2093, \n",
            "Step [1080/4000], d_real_loss: 0.1981, d_mnist_loss: 0.0333, d_svhn_loss: 0.1649, d_fake_loss: 0.0550, gen_loss_A: 1.1660, gen_loss_B: 1.0912,\n",
            "reconst_loss_A: 0.2154, recons_loss_B: 0.2104, \n",
            "Step [1090/4000], d_real_loss: 0.1810, d_mnist_loss: 0.0206, d_svhn_loss: 0.1603, d_fake_loss: 0.3416, gen_loss_A: 1.1231, gen_loss_B: 2.1384,\n",
            "reconst_loss_A: 0.1782, recons_loss_B: 0.1710, \n",
            "Step [1100/4000], d_real_loss: 0.2802, d_mnist_loss: 0.0434, d_svhn_loss: 0.2367, d_fake_loss: 0.1264, gen_loss_A: 1.0369, gen_loss_B: 1.3186,\n",
            "reconst_loss_A: 0.2012, recons_loss_B: 0.2752, \n",
            "saved ./samples/sample-1100-m-s.png\n",
            "saved ./samples/sample-1100-s-m.png\n",
            "Step [1110/4000], d_real_loss: 0.6034, d_mnist_loss: 0.2402, d_svhn_loss: 0.3632, d_fake_loss: 0.1822, gen_loss_A: 1.1797, gen_loss_B: 1.1637,\n",
            "reconst_loss_A: 0.1522, recons_loss_B: 0.2126, \n",
            "Step [1120/4000], d_real_loss: 0.1782, d_mnist_loss: 0.0914, d_svhn_loss: 0.0868, d_fake_loss: 0.4813, gen_loss_A: 1.6655, gen_loss_B: 1.3662,\n",
            "reconst_loss_A: 0.2200, recons_loss_B: 0.2151, \n",
            "Step [1130/4000], d_real_loss: 0.2802, d_mnist_loss: 0.1873, d_svhn_loss: 0.0929, d_fake_loss: 0.2929, gen_loss_A: 1.3678, gen_loss_B: 0.9962,\n",
            "reconst_loss_A: 0.1673, recons_loss_B: 0.1405, \n",
            "Step [1140/4000], d_real_loss: 0.1031, d_mnist_loss: 0.0432, d_svhn_loss: 0.0599, d_fake_loss: 0.0917, gen_loss_A: 1.1812, gen_loss_B: 0.9397,\n",
            "reconst_loss_A: 0.1939, recons_loss_B: 0.1276, \n",
            "Step [1150/4000], d_real_loss: 0.1625, d_mnist_loss: 0.0232, d_svhn_loss: 0.1393, d_fake_loss: 0.3094, gen_loss_A: 1.6627, gen_loss_B: 0.9881,\n",
            "reconst_loss_A: 0.2016, recons_loss_B: 0.1659, \n",
            "saved ./samples/sample-1150-m-s.png\n",
            "saved ./samples/sample-1150-s-m.png\n",
            "Step [1160/4000], d_real_loss: 0.1666, d_mnist_loss: 0.0529, d_svhn_loss: 0.1137, d_fake_loss: 0.2862, gen_loss_A: 1.3278, gen_loss_B: 1.3983,\n",
            "reconst_loss_A: 0.1799, recons_loss_B: 0.1404, \n",
            "Step [1170/4000], d_real_loss: 0.1573, d_mnist_loss: 0.0230, d_svhn_loss: 0.1343, d_fake_loss: 0.0997, gen_loss_A: 1.0381, gen_loss_B: 1.0616,\n",
            "reconst_loss_A: 0.1732, recons_loss_B: 0.3018, \n",
            "Step [1180/4000], d_real_loss: 0.1484, d_mnist_loss: 0.0341, d_svhn_loss: 0.1143, d_fake_loss: 0.1185, gen_loss_A: 1.0832, gen_loss_B: 1.5539,\n",
            "reconst_loss_A: 0.1611, recons_loss_B: 0.2565, \n",
            "Step [1190/4000], d_real_loss: 0.1362, d_mnist_loss: 0.0526, d_svhn_loss: 0.0837, d_fake_loss: 0.2166, gen_loss_A: 1.4145, gen_loss_B: 1.3265,\n",
            "reconst_loss_A: 0.1798, recons_loss_B: 0.1448, \n",
            "Step [1200/4000], d_real_loss: 0.1361, d_mnist_loss: 0.0676, d_svhn_loss: 0.0684, d_fake_loss: 0.2630, gen_loss_A: 1.5297, gen_loss_B: 1.7928,\n",
            "reconst_loss_A: 0.2182, recons_loss_B: 0.2714, \n",
            "saved ./samples/sample-1200-m-s.png\n",
            "saved ./samples/sample-1200-s-m.png\n",
            "Step [1210/4000], d_real_loss: 0.2166, d_mnist_loss: 0.0260, d_svhn_loss: 0.1905, d_fake_loss: 0.2280, gen_loss_A: 1.5794, gen_loss_B: 1.2138,\n",
            "reconst_loss_A: 0.1764, recons_loss_B: 0.2085, \n",
            "Step [1220/4000], d_real_loss: 0.4195, d_mnist_loss: 0.3091, d_svhn_loss: 0.1104, d_fake_loss: 0.5929, gen_loss_A: 1.8131, gen_loss_B: 1.4460,\n",
            "reconst_loss_A: 0.1650, recons_loss_B: 0.1920, \n",
            "Step [1230/4000], d_real_loss: 0.3082, d_mnist_loss: 0.0210, d_svhn_loss: 0.2872, d_fake_loss: 0.3497, gen_loss_A: 1.0569, gen_loss_B: 1.8673,\n",
            "reconst_loss_A: 0.1716, recons_loss_B: 0.1555, \n",
            "Step [1240/4000], d_real_loss: 0.1083, d_mnist_loss: 0.0683, d_svhn_loss: 0.0401, d_fake_loss: 0.2854, gen_loss_A: 1.7166, gen_loss_B: 0.9398,\n",
            "reconst_loss_A: 0.1724, recons_loss_B: 0.1565, \n",
            "Step [1250/4000], d_real_loss: 0.1634, d_mnist_loss: 0.0687, d_svhn_loss: 0.0946, d_fake_loss: 0.1229, gen_loss_A: 1.3189, gen_loss_B: 1.3602,\n",
            "reconst_loss_A: 0.1737, recons_loss_B: 0.1970, \n",
            "saved ./samples/sample-1250-m-s.png\n",
            "saved ./samples/sample-1250-s-m.png\n",
            "Step [1260/4000], d_real_loss: 0.2248, d_mnist_loss: 0.1900, d_svhn_loss: 0.0348, d_fake_loss: 0.3130, gen_loss_A: 1.4644, gen_loss_B: 1.1945,\n",
            "reconst_loss_A: 0.1798, recons_loss_B: 0.1967, \n",
            "Step [1270/4000], d_real_loss: 0.0690, d_mnist_loss: 0.0186, d_svhn_loss: 0.0504, d_fake_loss: 0.2180, gen_loss_A: 1.4181, gen_loss_B: 1.5247,\n",
            "reconst_loss_A: 0.1649, recons_loss_B: 0.2217, \n",
            "Step [1280/4000], d_real_loss: 0.3051, d_mnist_loss: 0.2507, d_svhn_loss: 0.0544, d_fake_loss: 0.1291, gen_loss_A: 1.5850, gen_loss_B: 0.9849,\n",
            "reconst_loss_A: 0.1935, recons_loss_B: 0.1568, \n",
            "Step [1290/4000], d_real_loss: 0.2481, d_mnist_loss: 0.1038, d_svhn_loss: 0.1443, d_fake_loss: 1.0051, gen_loss_A: 1.3880, gen_loss_B: 1.5823,\n",
            "reconst_loss_A: 0.2075, recons_loss_B: 0.2098, \n",
            "Step [1300/4000], d_real_loss: 0.5288, d_mnist_loss: 0.3273, d_svhn_loss: 0.2015, d_fake_loss: 0.1013, gen_loss_A: 1.1344, gen_loss_B: 0.9171,\n",
            "reconst_loss_A: 0.1934, recons_loss_B: 0.1428, \n",
            "saved ./samples/sample-1300-m-s.png\n",
            "saved ./samples/sample-1300-s-m.png\n",
            "Step [1310/4000], d_real_loss: 0.2077, d_mnist_loss: 0.1240, d_svhn_loss: 0.0837, d_fake_loss: 0.1804, gen_loss_A: 1.4456, gen_loss_B: 1.1746,\n",
            "reconst_loss_A: 0.1751, recons_loss_B: 0.1772, \n",
            "Step [1320/4000], d_real_loss: 0.2602, d_mnist_loss: 0.0177, d_svhn_loss: 0.2425, d_fake_loss: 0.0528, gen_loss_A: 1.0149, gen_loss_B: 1.1684,\n",
            "reconst_loss_A: 0.1664, recons_loss_B: 0.1533, \n",
            "Step [1330/4000], d_real_loss: 0.1196, d_mnist_loss: 0.0747, d_svhn_loss: 0.0449, d_fake_loss: 0.1553, gen_loss_A: 1.6403, gen_loss_B: 1.5308,\n",
            "reconst_loss_A: 0.2057, recons_loss_B: 0.2514, \n",
            "Step [1340/4000], d_real_loss: 0.2072, d_mnist_loss: 0.1372, d_svhn_loss: 0.0700, d_fake_loss: 0.2345, gen_loss_A: 1.4410, gen_loss_B: 1.4349,\n",
            "reconst_loss_A: 0.2035, recons_loss_B: 0.1188, \n",
            "Step [1350/4000], d_real_loss: 0.2542, d_mnist_loss: 0.1082, d_svhn_loss: 0.1460, d_fake_loss: 0.2456, gen_loss_A: 1.5105, gen_loss_B: 1.1456,\n",
            "reconst_loss_A: 0.1925, recons_loss_B: 0.1654, \n",
            "saved ./samples/sample-1350-m-s.png\n",
            "saved ./samples/sample-1350-s-m.png\n",
            "Step [1360/4000], d_real_loss: 0.1167, d_mnist_loss: 0.0436, d_svhn_loss: 0.0730, d_fake_loss: 0.0456, gen_loss_A: 1.4623, gen_loss_B: 1.4899,\n",
            "reconst_loss_A: 0.1552, recons_loss_B: 0.2117, \n",
            "Step [1370/4000], d_real_loss: 0.1121, d_mnist_loss: 0.0314, d_svhn_loss: 0.0807, d_fake_loss: 0.3709, gen_loss_A: 1.9266, gen_loss_B: 1.2985,\n",
            "reconst_loss_A: 0.1975, recons_loss_B: 0.2895, \n",
            "Step [1380/4000], d_real_loss: 0.2252, d_mnist_loss: 0.0367, d_svhn_loss: 0.1884, d_fake_loss: 0.2386, gen_loss_A: 0.9253, gen_loss_B: 1.3798,\n",
            "reconst_loss_A: 0.1821, recons_loss_B: 0.2678, \n",
            "Step [1390/4000], d_real_loss: 0.1190, d_mnist_loss: 0.0823, d_svhn_loss: 0.0367, d_fake_loss: 0.6009, gen_loss_A: 1.9804, gen_loss_B: 1.5290,\n",
            "reconst_loss_A: 0.1654, recons_loss_B: 0.1416, \n",
            "Step [1400/4000], d_real_loss: 0.1325, d_mnist_loss: 0.0329, d_svhn_loss: 0.0995, d_fake_loss: 0.1834, gen_loss_A: 1.1542, gen_loss_B: 1.6239,\n",
            "reconst_loss_A: 0.1833, recons_loss_B: 0.2202, \n",
            "saved ./samples/sample-1400-m-s.png\n",
            "saved ./samples/sample-1400-s-m.png\n",
            "Step [1410/4000], d_real_loss: 0.1405, d_mnist_loss: 0.0554, d_svhn_loss: 0.0851, d_fake_loss: 0.2812, gen_loss_A: 1.1997, gen_loss_B: 0.8448,\n",
            "reconst_loss_A: 0.1875, recons_loss_B: 0.1096, \n",
            "Step [1420/4000], d_real_loss: 0.2222, d_mnist_loss: 0.0303, d_svhn_loss: 0.1920, d_fake_loss: 0.0625, gen_loss_A: 1.1904, gen_loss_B: 1.4177,\n",
            "reconst_loss_A: 0.1863, recons_loss_B: 0.1994, \n",
            "Step [1430/4000], d_real_loss: 0.9765, d_mnist_loss: 0.0649, d_svhn_loss: 0.9116, d_fake_loss: 0.0834, gen_loss_A: 0.9650, gen_loss_B: 1.1232,\n",
            "reconst_loss_A: 0.2370, recons_loss_B: 0.2370, \n",
            "Step [1440/4000], d_real_loss: 0.1013, d_mnist_loss: 0.0246, d_svhn_loss: 0.0767, d_fake_loss: 0.1659, gen_loss_A: 1.3794, gen_loss_B: 0.8169,\n",
            "reconst_loss_A: 0.1734, recons_loss_B: 0.1127, \n",
            "Step [1450/4000], d_real_loss: 0.1449, d_mnist_loss: 0.0358, d_svhn_loss: 0.1090, d_fake_loss: 0.1487, gen_loss_A: 1.1891, gen_loss_B: 1.0916,\n",
            "reconst_loss_A: 0.1490, recons_loss_B: 0.2466, \n",
            "saved ./samples/sample-1450-m-s.png\n",
            "saved ./samples/sample-1450-s-m.png\n",
            "Step [1460/4000], d_real_loss: 0.3435, d_mnist_loss: 0.1161, d_svhn_loss: 0.2273, d_fake_loss: 0.1535, gen_loss_A: 1.3314, gen_loss_B: 1.2461,\n",
            "reconst_loss_A: 0.1555, recons_loss_B: 0.2071, \n",
            "Step [1470/4000], d_real_loss: 0.3606, d_mnist_loss: 0.1852, d_svhn_loss: 0.1754, d_fake_loss: 0.2901, gen_loss_A: 1.3852, gen_loss_B: 1.3203,\n",
            "reconst_loss_A: 0.1376, recons_loss_B: 0.1780, \n",
            "Step [1480/4000], d_real_loss: 0.7003, d_mnist_loss: 0.4453, d_svhn_loss: 0.2551, d_fake_loss: 0.5826, gen_loss_A: 1.2440, gen_loss_B: 1.7278,\n",
            "reconst_loss_A: 0.1895, recons_loss_B: 0.2307, \n",
            "Step [1490/4000], d_real_loss: 0.4784, d_mnist_loss: 0.3710, d_svhn_loss: 0.1074, d_fake_loss: 0.1720, gen_loss_A: 1.1854, gen_loss_B: 1.0067,\n",
            "reconst_loss_A: 0.1691, recons_loss_B: 0.1378, \n",
            "Step [1500/4000], d_real_loss: 0.3700, d_mnist_loss: 0.0767, d_svhn_loss: 0.2933, d_fake_loss: 0.3404, gen_loss_A: 1.4827, gen_loss_B: 1.1904,\n",
            "reconst_loss_A: 0.1755, recons_loss_B: 0.1382, \n",
            "saved ./samples/sample-1500-m-s.png\n",
            "saved ./samples/sample-1500-s-m.png\n",
            "Step [1510/4000], d_real_loss: 0.1164, d_mnist_loss: 0.0701, d_svhn_loss: 0.0464, d_fake_loss: 0.0506, gen_loss_A: 1.3662, gen_loss_B: 1.0643,\n",
            "reconst_loss_A: 0.1938, recons_loss_B: 0.1254, \n",
            "Step [1520/4000], d_real_loss: 0.1189, d_mnist_loss: 0.0478, d_svhn_loss: 0.0711, d_fake_loss: 0.0737, gen_loss_A: 1.5191, gen_loss_B: 1.2335,\n",
            "reconst_loss_A: 0.1831, recons_loss_B: 0.2158, \n",
            "Step [1530/4000], d_real_loss: 0.1207, d_mnist_loss: 0.0435, d_svhn_loss: 0.0772, d_fake_loss: 0.0760, gen_loss_A: 0.9993, gen_loss_B: 1.1907,\n",
            "reconst_loss_A: 0.1477, recons_loss_B: 0.2228, \n",
            "Step [1540/4000], d_real_loss: 0.5592, d_mnist_loss: 0.0672, d_svhn_loss: 0.4920, d_fake_loss: 0.1218, gen_loss_A: 1.0788, gen_loss_B: 1.5369,\n",
            "reconst_loss_A: 0.1799, recons_loss_B: 0.1547, \n",
            "Step [1550/4000], d_real_loss: 0.1147, d_mnist_loss: 0.0555, d_svhn_loss: 0.0592, d_fake_loss: 0.5727, gen_loss_A: 1.3959, gen_loss_B: 1.1998,\n",
            "reconst_loss_A: 0.1278, recons_loss_B: 0.1735, \n",
            "saved ./samples/sample-1550-m-s.png\n",
            "saved ./samples/sample-1550-s-m.png\n",
            "Step [1560/4000], d_real_loss: 0.3621, d_mnist_loss: 0.0173, d_svhn_loss: 0.3448, d_fake_loss: 0.3368, gen_loss_A: 1.2887, gen_loss_B: 1.3989,\n",
            "reconst_loss_A: 0.1708, recons_loss_B: 0.1882, \n",
            "Step [1570/4000], d_real_loss: 0.1670, d_mnist_loss: 0.0364, d_svhn_loss: 0.1306, d_fake_loss: 0.0384, gen_loss_A: 1.3113, gen_loss_B: 1.5785,\n",
            "reconst_loss_A: 0.1796, recons_loss_B: 0.1771, \n",
            "Step [1580/4000], d_real_loss: 0.2970, d_mnist_loss: 0.0686, d_svhn_loss: 0.2284, d_fake_loss: 0.0544, gen_loss_A: 1.0800, gen_loss_B: 0.8694,\n",
            "reconst_loss_A: 0.1930, recons_loss_B: 0.1396, \n",
            "Step [1590/4000], d_real_loss: 0.0742, d_mnist_loss: 0.0241, d_svhn_loss: 0.0501, d_fake_loss: 0.1358, gen_loss_A: 1.4354, gen_loss_B: 1.1707,\n",
            "reconst_loss_A: 0.1599, recons_loss_B: 0.1147, \n",
            "Step [1600/4000], d_real_loss: 0.0656, d_mnist_loss: 0.0223, d_svhn_loss: 0.0433, d_fake_loss: 0.2974, gen_loss_A: 1.8078, gen_loss_B: 1.4685,\n",
            "reconst_loss_A: 0.1648, recons_loss_B: 0.1746, \n",
            "saved ./samples/sample-1600-m-s.png\n",
            "saved ./samples/sample-1600-s-m.png\n",
            "Step [1610/4000], d_real_loss: 0.0704, d_mnist_loss: 0.0324, d_svhn_loss: 0.0380, d_fake_loss: 0.1425, gen_loss_A: 1.1002, gen_loss_B: 1.0968,\n",
            "reconst_loss_A: 0.2068, recons_loss_B: 0.1644, \n",
            "Step [1620/4000], d_real_loss: 0.1965, d_mnist_loss: 0.0376, d_svhn_loss: 0.1589, d_fake_loss: 0.0783, gen_loss_A: 1.2023, gen_loss_B: 1.2615,\n",
            "reconst_loss_A: 0.1790, recons_loss_B: 0.1874, \n",
            "Step [1630/4000], d_real_loss: 0.3871, d_mnist_loss: 0.0382, d_svhn_loss: 0.3488, d_fake_loss: 0.1053, gen_loss_A: 0.8594, gen_loss_B: 1.0654,\n",
            "reconst_loss_A: 0.1523, recons_loss_B: 0.1203, \n",
            "Step [1640/4000], d_real_loss: 0.1964, d_mnist_loss: 0.0521, d_svhn_loss: 0.1442, d_fake_loss: 0.0687, gen_loss_A: 1.1571, gen_loss_B: 1.0050,\n",
            "reconst_loss_A: 0.1593, recons_loss_B: 0.1417, \n",
            "Step [1650/4000], d_real_loss: 0.0767, d_mnist_loss: 0.0378, d_svhn_loss: 0.0389, d_fake_loss: 0.0473, gen_loss_A: 1.2895, gen_loss_B: 1.1011,\n",
            "reconst_loss_A: 0.1526, recons_loss_B: 0.1522, \n",
            "saved ./samples/sample-1650-m-s.png\n",
            "saved ./samples/sample-1650-s-m.png\n",
            "Step [1660/4000], d_real_loss: 0.1504, d_mnist_loss: 0.0812, d_svhn_loss: 0.0692, d_fake_loss: 0.2664, gen_loss_A: 1.1577, gen_loss_B: 1.6537,\n",
            "reconst_loss_A: 0.2139, recons_loss_B: 0.1852, \n",
            "Step [1670/4000], d_real_loss: 0.2156, d_mnist_loss: 0.1294, d_svhn_loss: 0.0862, d_fake_loss: 0.1316, gen_loss_A: 1.2276, gen_loss_B: 1.3326,\n",
            "reconst_loss_A: 0.1734, recons_loss_B: 0.1699, \n",
            "Step [1680/4000], d_real_loss: 0.1096, d_mnist_loss: 0.0670, d_svhn_loss: 0.0426, d_fake_loss: 0.1523, gen_loss_A: 1.3890, gen_loss_B: 1.1094,\n",
            "reconst_loss_A: 0.2048, recons_loss_B: 0.2208, \n",
            "Step [1690/4000], d_real_loss: 0.1174, d_mnist_loss: 0.0522, d_svhn_loss: 0.0652, d_fake_loss: 0.2092, gen_loss_A: 1.5703, gen_loss_B: 1.6328,\n",
            "reconst_loss_A: 0.1614, recons_loss_B: 0.1734, \n",
            "Step [1700/4000], d_real_loss: 0.1982, d_mnist_loss: 0.0328, d_svhn_loss: 0.1654, d_fake_loss: 0.0456, gen_loss_A: 1.0459, gen_loss_B: 1.1592,\n",
            "reconst_loss_A: 0.1699, recons_loss_B: 0.1977, \n",
            "saved ./samples/sample-1700-m-s.png\n",
            "saved ./samples/sample-1700-s-m.png\n",
            "Step [1710/4000], d_real_loss: 0.1080, d_mnist_loss: 0.0422, d_svhn_loss: 0.0658, d_fake_loss: 0.0702, gen_loss_A: 1.2199, gen_loss_B: 1.1082,\n",
            "reconst_loss_A: 0.1911, recons_loss_B: 0.2075, \n",
            "Step [1720/4000], d_real_loss: 0.1625, d_mnist_loss: 0.0878, d_svhn_loss: 0.0747, d_fake_loss: 0.1723, gen_loss_A: 1.8644, gen_loss_B: 1.5731,\n",
            "reconst_loss_A: 0.2144, recons_loss_B: 0.1980, \n",
            "Step [1730/4000], d_real_loss: 0.3297, d_mnist_loss: 0.1189, d_svhn_loss: 0.2108, d_fake_loss: 0.1160, gen_loss_A: 1.3072, gen_loss_B: 1.1513,\n",
            "reconst_loss_A: 0.1964, recons_loss_B: 0.2161, \n",
            "Step [1740/4000], d_real_loss: 0.1859, d_mnist_loss: 0.0501, d_svhn_loss: 0.1358, d_fake_loss: 0.1034, gen_loss_A: 1.7409, gen_loss_B: 1.3990,\n",
            "reconst_loss_A: 0.1890, recons_loss_B: 0.2132, \n",
            "Step [1750/4000], d_real_loss: 0.1518, d_mnist_loss: 0.0389, d_svhn_loss: 0.1129, d_fake_loss: 0.1090, gen_loss_A: 1.2531, gen_loss_B: 1.2902,\n",
            "reconst_loss_A: 0.1875, recons_loss_B: 0.2288, \n",
            "saved ./samples/sample-1750-m-s.png\n",
            "saved ./samples/sample-1750-s-m.png\n",
            "Step [1760/4000], d_real_loss: 0.2359, d_mnist_loss: 0.0579, d_svhn_loss: 0.1780, d_fake_loss: 0.1807, gen_loss_A: 1.2394, gen_loss_B: 1.5142,\n",
            "reconst_loss_A: 0.1388, recons_loss_B: 0.2177, \n",
            "Step [1770/4000], d_real_loss: 0.1067, d_mnist_loss: 0.0644, d_svhn_loss: 0.0423, d_fake_loss: 0.0480, gen_loss_A: 1.2416, gen_loss_B: 1.1636,\n",
            "reconst_loss_A: 0.1945, recons_loss_B: 0.1441, \n",
            "Step [1780/4000], d_real_loss: 0.1881, d_mnist_loss: 0.0404, d_svhn_loss: 0.1477, d_fake_loss: 1.0154, gen_loss_A: 2.1181, gen_loss_B: 1.4128,\n",
            "reconst_loss_A: 0.1641, recons_loss_B: 0.1957, \n",
            "Step [1790/4000], d_real_loss: 0.2044, d_mnist_loss: 0.0463, d_svhn_loss: 0.1582, d_fake_loss: 0.1104, gen_loss_A: 1.1256, gen_loss_B: 1.4912,\n",
            "reconst_loss_A: 0.1544, recons_loss_B: 0.1971, \n",
            "Step [1800/4000], d_real_loss: 0.0885, d_mnist_loss: 0.0542, d_svhn_loss: 0.0343, d_fake_loss: 0.1190, gen_loss_A: 1.4494, gen_loss_B: 1.5711,\n",
            "reconst_loss_A: 0.1570, recons_loss_B: 0.1794, \n",
            "saved ./samples/sample-1800-m-s.png\n",
            "saved ./samples/sample-1800-s-m.png\n",
            "Step [1810/4000], d_real_loss: 0.3094, d_mnist_loss: 0.0782, d_svhn_loss: 0.2312, d_fake_loss: 0.1510, gen_loss_A: 0.9579, gen_loss_B: 2.5157,\n",
            "reconst_loss_A: 0.1362, recons_loss_B: 0.2177, \n",
            "Step [1820/4000], d_real_loss: 0.3509, d_mnist_loss: 0.2311, d_svhn_loss: 0.1198, d_fake_loss: 0.1336, gen_loss_A: 1.3365, gen_loss_B: 0.9684,\n",
            "reconst_loss_A: 0.1952, recons_loss_B: 0.1855, \n",
            "Step [1830/4000], d_real_loss: 0.1096, d_mnist_loss: 0.0419, d_svhn_loss: 0.0677, d_fake_loss: 0.1420, gen_loss_A: 1.3919, gen_loss_B: 1.3955,\n",
            "reconst_loss_A: 0.1882, recons_loss_B: 0.2153, \n",
            "Step [1840/4000], d_real_loss: 0.1606, d_mnist_loss: 0.0197, d_svhn_loss: 0.1409, d_fake_loss: 0.1072, gen_loss_A: 1.1874, gen_loss_B: 0.9746,\n",
            "reconst_loss_A: 0.1877, recons_loss_B: 0.1858, \n",
            "Step [1850/4000], d_real_loss: 0.1848, d_mnist_loss: 0.0532, d_svhn_loss: 0.1316, d_fake_loss: 0.0512, gen_loss_A: 1.2719, gen_loss_B: 1.0587,\n",
            "reconst_loss_A: 0.2209, recons_loss_B: 0.2056, \n",
            "saved ./samples/sample-1850-m-s.png\n",
            "saved ./samples/sample-1850-s-m.png\n",
            "Step [1860/4000], d_real_loss: 0.1236, d_mnist_loss: 0.0726, d_svhn_loss: 0.0510, d_fake_loss: 0.6626, gen_loss_A: 1.6297, gen_loss_B: 1.2947,\n",
            "reconst_loss_A: 0.1850, recons_loss_B: 0.2349, \n",
            "Step [1870/4000], d_real_loss: 0.0835, d_mnist_loss: 0.0579, d_svhn_loss: 0.0257, d_fake_loss: 0.0513, gen_loss_A: 1.1614, gen_loss_B: 1.2487,\n",
            "reconst_loss_A: 0.1727, recons_loss_B: 0.1137, \n",
            "Step [1880/4000], d_real_loss: 0.0549, d_mnist_loss: 0.0176, d_svhn_loss: 0.0373, d_fake_loss: 0.0942, gen_loss_A: 1.3960, gen_loss_B: 0.9675,\n",
            "reconst_loss_A: 0.1815, recons_loss_B: 0.1175, \n",
            "Step [1890/4000], d_real_loss: 0.0979, d_mnist_loss: 0.0299, d_svhn_loss: 0.0680, d_fake_loss: 0.0764, gen_loss_A: 1.2229, gen_loss_B: 1.2849,\n",
            "reconst_loss_A: 0.1457, recons_loss_B: 0.1694, \n",
            "Step [1900/4000], d_real_loss: 0.1120, d_mnist_loss: 0.0533, d_svhn_loss: 0.0587, d_fake_loss: 0.4527, gen_loss_A: 1.2570, gen_loss_B: 1.4068,\n",
            "reconst_loss_A: 0.2072, recons_loss_B: 0.1747, \n",
            "saved ./samples/sample-1900-m-s.png\n",
            "saved ./samples/sample-1900-s-m.png\n",
            "Step [1910/4000], d_real_loss: 0.1959, d_mnist_loss: 0.0797, d_svhn_loss: 0.1162, d_fake_loss: 0.1977, gen_loss_A: 1.1759, gen_loss_B: 1.3498,\n",
            "reconst_loss_A: 0.1688, recons_loss_B: 0.1679, \n",
            "Step [1920/4000], d_real_loss: 0.1752, d_mnist_loss: 0.1212, d_svhn_loss: 0.0540, d_fake_loss: 0.1454, gen_loss_A: 1.3784, gen_loss_B: 1.3878,\n",
            "reconst_loss_A: 0.2119, recons_loss_B: 0.1055, \n",
            "Step [1930/4000], d_real_loss: 0.3887, d_mnist_loss: 0.0241, d_svhn_loss: 0.3646, d_fake_loss: 0.1143, gen_loss_A: 1.3646, gen_loss_B: 1.1474,\n",
            "reconst_loss_A: 0.1796, recons_loss_B: 0.1597, \n",
            "Step [1940/4000], d_real_loss: 0.1954, d_mnist_loss: 0.1164, d_svhn_loss: 0.0789, d_fake_loss: 0.0532, gen_loss_A: 1.3106, gen_loss_B: 1.0403,\n",
            "reconst_loss_A: 0.1961, recons_loss_B: 0.1615, \n",
            "Step [1950/4000], d_real_loss: 0.1365, d_mnist_loss: 0.0696, d_svhn_loss: 0.0669, d_fake_loss: 0.3608, gen_loss_A: 1.6694, gen_loss_B: 1.1532,\n",
            "reconst_loss_A: 0.1818, recons_loss_B: 0.2404, \n",
            "saved ./samples/sample-1950-m-s.png\n",
            "saved ./samples/sample-1950-s-m.png\n",
            "Step [1960/4000], d_real_loss: 0.0743, d_mnist_loss: 0.0259, d_svhn_loss: 0.0484, d_fake_loss: 0.0919, gen_loss_A: 1.3114, gen_loss_B: 1.2061,\n",
            "reconst_loss_A: 0.1772, recons_loss_B: 0.1512, \n",
            "Step [1970/4000], d_real_loss: 0.1101, d_mnist_loss: 0.0518, d_svhn_loss: 0.0583, d_fake_loss: 0.3089, gen_loss_A: 1.7018, gen_loss_B: 1.3267,\n",
            "reconst_loss_A: 0.1722, recons_loss_B: 0.1843, \n",
            "Step [1980/4000], d_real_loss: 0.2515, d_mnist_loss: 0.0366, d_svhn_loss: 0.2148, d_fake_loss: 0.1231, gen_loss_A: 1.0661, gen_loss_B: 1.4359,\n",
            "reconst_loss_A: 0.1779, recons_loss_B: 0.1923, \n",
            "Step [1990/4000], d_real_loss: 0.3080, d_mnist_loss: 0.0384, d_svhn_loss: 0.2697, d_fake_loss: 0.1589, gen_loss_A: 0.9969, gen_loss_B: 1.5737,\n",
            "reconst_loss_A: 0.1854, recons_loss_B: 0.1675, \n",
            "Step [2000/4000], d_real_loss: 0.1414, d_mnist_loss: 0.0274, d_svhn_loss: 0.1140, d_fake_loss: 0.1835, gen_loss_A: 1.3667, gen_loss_B: 1.4791,\n",
            "reconst_loss_A: 0.1933, recons_loss_B: 0.2075, \n",
            "saved ./samples/sample-2000-m-s.png\n",
            "saved ./samples/sample-2000-s-m.png\n",
            "Step [2010/4000], d_real_loss: 0.0936, d_mnist_loss: 0.0308, d_svhn_loss: 0.0628, d_fake_loss: 0.1614, gen_loss_A: 1.3283, gen_loss_B: 1.4801,\n",
            "reconst_loss_A: 0.2087, recons_loss_B: 0.2250, \n",
            "Step [2020/4000], d_real_loss: 0.1500, d_mnist_loss: 0.0719, d_svhn_loss: 0.0781, d_fake_loss: 0.3122, gen_loss_A: 1.7228, gen_loss_B: 1.1259,\n",
            "reconst_loss_A: 0.1478, recons_loss_B: 0.1186, \n",
            "Step [2030/4000], d_real_loss: 0.2057, d_mnist_loss: 0.0887, d_svhn_loss: 0.1170, d_fake_loss: 0.1528, gen_loss_A: 1.3218, gen_loss_B: 1.0526,\n",
            "reconst_loss_A: 0.1726, recons_loss_B: 0.1446, \n",
            "Step [2040/4000], d_real_loss: 0.0966, d_mnist_loss: 0.0647, d_svhn_loss: 0.0318, d_fake_loss: 0.1561, gen_loss_A: 1.3856, gen_loss_B: 1.1731,\n",
            "reconst_loss_A: 0.1361, recons_loss_B: 0.1615, \n",
            "Step [2050/4000], d_real_loss: 0.3323, d_mnist_loss: 0.2299, d_svhn_loss: 0.1023, d_fake_loss: 0.4445, gen_loss_A: 1.8709, gen_loss_B: 1.1737,\n",
            "reconst_loss_A: 0.1853, recons_loss_B: 0.1396, \n",
            "saved ./samples/sample-2050-m-s.png\n",
            "saved ./samples/sample-2050-s-m.png\n",
            "Step [2060/4000], d_real_loss: 0.0917, d_mnist_loss: 0.0223, d_svhn_loss: 0.0694, d_fake_loss: 0.0726, gen_loss_A: 1.1556, gen_loss_B: 1.2084,\n",
            "reconst_loss_A: 0.1620, recons_loss_B: 0.1528, \n",
            "Step [2070/4000], d_real_loss: 0.5105, d_mnist_loss: 0.0646, d_svhn_loss: 0.4459, d_fake_loss: 0.1512, gen_loss_A: 1.0144, gen_loss_B: 1.2850,\n",
            "reconst_loss_A: 0.1940, recons_loss_B: 0.1490, \n",
            "Step [2080/4000], d_real_loss: 0.4084, d_mnist_loss: 0.0306, d_svhn_loss: 0.3778, d_fake_loss: 0.0547, gen_loss_A: 1.1140, gen_loss_B: 1.0908,\n",
            "reconst_loss_A: 0.1847, recons_loss_B: 0.1653, \n",
            "Step [2090/4000], d_real_loss: 0.0910, d_mnist_loss: 0.0279, d_svhn_loss: 0.0631, d_fake_loss: 0.1270, gen_loss_A: 1.7551, gen_loss_B: 1.1861,\n",
            "reconst_loss_A: 0.2527, recons_loss_B: 0.2384, \n",
            "Step [2100/4000], d_real_loss: 0.1573, d_mnist_loss: 0.0458, d_svhn_loss: 0.1115, d_fake_loss: 0.0570, gen_loss_A: 1.0794, gen_loss_B: 1.4368,\n",
            "reconst_loss_A: 0.1661, recons_loss_B: 0.1941, \n",
            "saved ./samples/sample-2100-m-s.png\n",
            "saved ./samples/sample-2100-s-m.png\n",
            "Step [2110/4000], d_real_loss: 0.1702, d_mnist_loss: 0.1167, d_svhn_loss: 0.0535, d_fake_loss: 0.0853, gen_loss_A: 1.2357, gen_loss_B: 1.0641,\n",
            "reconst_loss_A: 0.1505, recons_loss_B: 0.2121, \n",
            "Step [2120/4000], d_real_loss: 0.4658, d_mnist_loss: 0.3429, d_svhn_loss: 0.1229, d_fake_loss: 0.1119, gen_loss_A: 1.2174, gen_loss_B: 1.0563,\n",
            "reconst_loss_A: 0.1672, recons_loss_B: 0.1860, \n",
            "Step [2130/4000], d_real_loss: 0.3325, d_mnist_loss: 0.0539, d_svhn_loss: 0.2786, d_fake_loss: 0.1086, gen_loss_A: 1.2120, gen_loss_B: 1.4224,\n",
            "reconst_loss_A: 0.1910, recons_loss_B: 0.1735, \n",
            "Step [2140/4000], d_real_loss: 0.0327, d_mnist_loss: 0.0151, d_svhn_loss: 0.0175, d_fake_loss: 0.1844, gen_loss_A: 1.5576, gen_loss_B: 1.8126,\n",
            "reconst_loss_A: 0.1777, recons_loss_B: 0.1919, \n",
            "Step [2150/4000], d_real_loss: 0.1548, d_mnist_loss: 0.0859, d_svhn_loss: 0.0689, d_fake_loss: 0.1444, gen_loss_A: 1.2041, gen_loss_B: 1.0935,\n",
            "reconst_loss_A: 0.1824, recons_loss_B: 0.1055, \n",
            "saved ./samples/sample-2150-m-s.png\n",
            "saved ./samples/sample-2150-s-m.png\n",
            "Step [2160/4000], d_real_loss: 0.0797, d_mnist_loss: 0.0218, d_svhn_loss: 0.0579, d_fake_loss: 0.4598, gen_loss_A: 2.1860, gen_loss_B: 1.1942,\n",
            "reconst_loss_A: 0.1714, recons_loss_B: 0.1930, \n",
            "Step [2170/4000], d_real_loss: 0.1991, d_mnist_loss: 0.1207, d_svhn_loss: 0.0784, d_fake_loss: 0.1604, gen_loss_A: 1.4083, gen_loss_B: 0.8759,\n",
            "reconst_loss_A: 0.1667, recons_loss_B: 0.1619, \n",
            "Step [2180/4000], d_real_loss: 0.1602, d_mnist_loss: 0.0077, d_svhn_loss: 0.1525, d_fake_loss: 0.0635, gen_loss_A: 1.0689, gen_loss_B: 1.2236,\n",
            "reconst_loss_A: 0.1901, recons_loss_B: 0.1843, \n",
            "Step [2190/4000], d_real_loss: 0.0614, d_mnist_loss: 0.0256, d_svhn_loss: 0.0358, d_fake_loss: 0.1727, gen_loss_A: 1.4489, gen_loss_B: 0.8067,\n",
            "reconst_loss_A: 0.1794, recons_loss_B: 0.1274, \n",
            "Step [2200/4000], d_real_loss: 0.2355, d_mnist_loss: 0.0147, d_svhn_loss: 0.2208, d_fake_loss: 0.5555, gen_loss_A: 1.8521, gen_loss_B: 1.2576,\n",
            "reconst_loss_A: 0.2194, recons_loss_B: 0.1792, \n",
            "saved ./samples/sample-2200-m-s.png\n",
            "saved ./samples/sample-2200-s-m.png\n",
            "Step [2210/4000], d_real_loss: 0.1504, d_mnist_loss: 0.0979, d_svhn_loss: 0.0525, d_fake_loss: 0.3407, gen_loss_A: 1.3260, gen_loss_B: 1.7827,\n",
            "reconst_loss_A: 0.1990, recons_loss_B: 0.1479, \n",
            "Step [2220/4000], d_real_loss: 0.0824, d_mnist_loss: 0.0135, d_svhn_loss: 0.0690, d_fake_loss: 0.0844, gen_loss_A: 1.0668, gen_loss_B: 1.0978,\n",
            "reconst_loss_A: 0.1587, recons_loss_B: 0.1872, \n",
            "Step [2230/4000], d_real_loss: 0.1365, d_mnist_loss: 0.0797, d_svhn_loss: 0.0569, d_fake_loss: 0.2023, gen_loss_A: 1.4565, gen_loss_B: 1.2973,\n",
            "reconst_loss_A: 0.1832, recons_loss_B: 0.1392, \n",
            "Step [2240/4000], d_real_loss: 0.0657, d_mnist_loss: 0.0249, d_svhn_loss: 0.0408, d_fake_loss: 0.1511, gen_loss_A: 1.0306, gen_loss_B: 1.4668,\n",
            "reconst_loss_A: 0.1416, recons_loss_B: 0.1714, \n",
            "Step [2250/4000], d_real_loss: 0.0522, d_mnist_loss: 0.0170, d_svhn_loss: 0.0352, d_fake_loss: 0.3746, gen_loss_A: 1.8557, gen_loss_B: 1.1095,\n",
            "reconst_loss_A: 0.1939, recons_loss_B: 0.1385, \n",
            "saved ./samples/sample-2250-m-s.png\n",
            "saved ./samples/sample-2250-s-m.png\n",
            "Step [2260/4000], d_real_loss: 0.1512, d_mnist_loss: 0.0876, d_svhn_loss: 0.0636, d_fake_loss: 0.1550, gen_loss_A: 1.6485, gen_loss_B: 1.1258,\n",
            "reconst_loss_A: 0.2036, recons_loss_B: 0.2068, \n",
            "Step [2270/4000], d_real_loss: 0.8124, d_mnist_loss: 0.2252, d_svhn_loss: 0.5872, d_fake_loss: 0.1437, gen_loss_A: 1.0871, gen_loss_B: 1.0487,\n",
            "reconst_loss_A: 0.1886, recons_loss_B: 0.1524, \n",
            "Step [2280/4000], d_real_loss: 0.1368, d_mnist_loss: 0.0884, d_svhn_loss: 0.0484, d_fake_loss: 0.2129, gen_loss_A: 1.4673, gen_loss_B: 1.4085,\n",
            "reconst_loss_A: 0.1814, recons_loss_B: 0.1565, \n",
            "Step [2290/4000], d_real_loss: 0.1380, d_mnist_loss: 0.0907, d_svhn_loss: 0.0473, d_fake_loss: 0.2266, gen_loss_A: 1.4732, gen_loss_B: 1.1268,\n",
            "reconst_loss_A: 0.1392, recons_loss_B: 0.1627, \n",
            "Step [2300/4000], d_real_loss: 0.1968, d_mnist_loss: 0.0345, d_svhn_loss: 0.1622, d_fake_loss: 0.2893, gen_loss_A: 1.1895, gen_loss_B: 1.4676,\n",
            "reconst_loss_A: 0.1344, recons_loss_B: 0.1484, \n",
            "saved ./samples/sample-2300-m-s.png\n",
            "saved ./samples/sample-2300-s-m.png\n",
            "Step [2310/4000], d_real_loss: 0.1467, d_mnist_loss: 0.0660, d_svhn_loss: 0.0808, d_fake_loss: 0.0484, gen_loss_A: 1.1978, gen_loss_B: 1.0731,\n",
            "reconst_loss_A: 0.1639, recons_loss_B: 0.1524, \n",
            "Step [2320/4000], d_real_loss: 0.1527, d_mnist_loss: 0.0310, d_svhn_loss: 0.1217, d_fake_loss: 0.1154, gen_loss_A: 1.4059, gen_loss_B: 1.6572,\n",
            "reconst_loss_A: 0.1868, recons_loss_B: 0.1858, \n",
            "Step [2330/4000], d_real_loss: 0.6428, d_mnist_loss: 0.4783, d_svhn_loss: 0.1644, d_fake_loss: 0.3816, gen_loss_A: 1.3928, gen_loss_B: 1.3718,\n",
            "reconst_loss_A: 0.1703, recons_loss_B: 0.1618, \n",
            "Step [2340/4000], d_real_loss: 0.1524, d_mnist_loss: 0.1163, d_svhn_loss: 0.0361, d_fake_loss: 0.1658, gen_loss_A: 1.5271, gen_loss_B: 1.3264,\n",
            "reconst_loss_A: 0.2152, recons_loss_B: 0.2492, \n",
            "Step [2350/4000], d_real_loss: 0.0803, d_mnist_loss: 0.0175, d_svhn_loss: 0.0629, d_fake_loss: 0.0978, gen_loss_A: 1.2002, gen_loss_B: 1.3697,\n",
            "reconst_loss_A: 0.1544, recons_loss_B: 0.1662, \n",
            "saved ./samples/sample-2350-m-s.png\n",
            "saved ./samples/sample-2350-s-m.png\n",
            "Step [2360/4000], d_real_loss: 0.4152, d_mnist_loss: 0.1729, d_svhn_loss: 0.2422, d_fake_loss: 0.9622, gen_loss_A: 1.6057, gen_loss_B: 1.3980,\n",
            "reconst_loss_A: 0.1884, recons_loss_B: 0.1236, \n",
            "Step [2370/4000], d_real_loss: 0.3268, d_mnist_loss: 0.1076, d_svhn_loss: 0.2192, d_fake_loss: 0.1211, gen_loss_A: 1.1109, gen_loss_B: 1.1186,\n",
            "reconst_loss_A: 0.1539, recons_loss_B: 0.1567, \n",
            "Step [2380/4000], d_real_loss: 0.3097, d_mnist_loss: 0.2710, d_svhn_loss: 0.0387, d_fake_loss: 0.1715, gen_loss_A: 1.4402, gen_loss_B: 0.9232,\n",
            "reconst_loss_A: 0.1607, recons_loss_B: 0.1275, \n",
            "Step [2390/4000], d_real_loss: 0.1534, d_mnist_loss: 0.1108, d_svhn_loss: 0.0426, d_fake_loss: 0.0858, gen_loss_A: 1.7117, gen_loss_B: 1.1589,\n",
            "reconst_loss_A: 0.1612, recons_loss_B: 0.2090, \n",
            "Step [2400/4000], d_real_loss: 0.1074, d_mnist_loss: 0.0475, d_svhn_loss: 0.0599, d_fake_loss: 0.1939, gen_loss_A: 1.6341, gen_loss_B: 1.5733,\n",
            "reconst_loss_A: 0.1325, recons_loss_B: 0.1515, \n",
            "saved ./samples/sample-2400-m-s.png\n",
            "saved ./samples/sample-2400-s-m.png\n",
            "Step [2410/4000], d_real_loss: 0.0905, d_mnist_loss: 0.0621, d_svhn_loss: 0.0285, d_fake_loss: 0.2586, gen_loss_A: 1.4556, gen_loss_B: 1.2455,\n",
            "reconst_loss_A: 0.1546, recons_loss_B: 0.2040, \n",
            "Step [2420/4000], d_real_loss: 0.0979, d_mnist_loss: 0.0795, d_svhn_loss: 0.0184, d_fake_loss: 0.3580, gen_loss_A: 1.2029, gen_loss_B: 1.5169,\n",
            "reconst_loss_A: 0.1636, recons_loss_B: 0.1474, \n",
            "Step [2430/4000], d_real_loss: 0.1026, d_mnist_loss: 0.0295, d_svhn_loss: 0.0731, d_fake_loss: 0.1371, gen_loss_A: 0.9294, gen_loss_B: 1.2955,\n",
            "reconst_loss_A: 0.1666, recons_loss_B: 0.1684, \n",
            "Step [2440/4000], d_real_loss: 0.2569, d_mnist_loss: 0.1076, d_svhn_loss: 0.1493, d_fake_loss: 0.2983, gen_loss_A: 1.0658, gen_loss_B: 1.4909,\n",
            "reconst_loss_A: 0.1452, recons_loss_B: 0.1557, \n",
            "Step [2450/4000], d_real_loss: 0.1444, d_mnist_loss: 0.0639, d_svhn_loss: 0.0805, d_fake_loss: 0.1089, gen_loss_A: 1.4517, gen_loss_B: 1.0959,\n",
            "reconst_loss_A: 0.1832, recons_loss_B: 0.1947, \n",
            "saved ./samples/sample-2450-m-s.png\n",
            "saved ./samples/sample-2450-s-m.png\n",
            "Step [2460/4000], d_real_loss: 0.1810, d_mnist_loss: 0.0186, d_svhn_loss: 0.1624, d_fake_loss: 0.0833, gen_loss_A: 1.2264, gen_loss_B: 0.9142,\n",
            "reconst_loss_A: 0.1984, recons_loss_B: 0.1652, \n",
            "Step [2470/4000], d_real_loss: 0.0929, d_mnist_loss: 0.0310, d_svhn_loss: 0.0619, d_fake_loss: 0.0640, gen_loss_A: 1.1318, gen_loss_B: 1.3682,\n",
            "reconst_loss_A: 0.1366, recons_loss_B: 0.1903, \n",
            "Step [2480/4000], d_real_loss: 0.1190, d_mnist_loss: 0.0259, d_svhn_loss: 0.0932, d_fake_loss: 0.5304, gen_loss_A: 1.8909, gen_loss_B: 1.1778,\n",
            "reconst_loss_A: 0.1869, recons_loss_B: 0.1857, \n",
            "Step [2490/4000], d_real_loss: 0.1407, d_mnist_loss: 0.1082, d_svhn_loss: 0.0325, d_fake_loss: 0.1933, gen_loss_A: 1.5615, gen_loss_B: 0.9921,\n",
            "reconst_loss_A: 0.2202, recons_loss_B: 0.1655, \n",
            "Step [2500/4000], d_real_loss: 0.0823, d_mnist_loss: 0.0230, d_svhn_loss: 0.0593, d_fake_loss: 0.4308, gen_loss_A: 1.8766, gen_loss_B: 1.4702,\n",
            "reconst_loss_A: 0.1543, recons_loss_B: 0.2373, \n",
            "saved ./samples/sample-2500-m-s.png\n",
            "saved ./samples/sample-2500-s-m.png\n",
            "Step [2510/4000], d_real_loss: 0.2268, d_mnist_loss: 0.1256, d_svhn_loss: 0.1012, d_fake_loss: 0.5625, gen_loss_A: 1.1544, gen_loss_B: 2.0458,\n",
            "reconst_loss_A: 0.1921, recons_loss_B: 0.2203, \n",
            "Step [2520/4000], d_real_loss: 0.0398, d_mnist_loss: 0.0189, d_svhn_loss: 0.0209, d_fake_loss: 0.3745, gen_loss_A: 1.9645, gen_loss_B: 1.1394,\n",
            "reconst_loss_A: 0.1583, recons_loss_B: 0.1297, \n",
            "Step [2530/4000], d_real_loss: 0.1444, d_mnist_loss: 0.0979, d_svhn_loss: 0.0465, d_fake_loss: 0.2104, gen_loss_A: 1.7270, gen_loss_B: 1.2284,\n",
            "reconst_loss_A: 0.1737, recons_loss_B: 0.1569, \n",
            "Step [2540/4000], d_real_loss: 0.1133, d_mnist_loss: 0.0387, d_svhn_loss: 0.0746, d_fake_loss: 0.0720, gen_loss_A: 1.4266, gen_loss_B: 1.3008,\n",
            "reconst_loss_A: 0.1342, recons_loss_B: 0.1816, \n",
            "Step [2550/4000], d_real_loss: 0.1521, d_mnist_loss: 0.0735, d_svhn_loss: 0.0786, d_fake_loss: 0.1107, gen_loss_A: 1.1792, gen_loss_B: 1.2414,\n",
            "reconst_loss_A: 0.1661, recons_loss_B: 0.1435, \n",
            "saved ./samples/sample-2550-m-s.png\n",
            "saved ./samples/sample-2550-s-m.png\n",
            "Step [2560/4000], d_real_loss: 0.0532, d_mnist_loss: 0.0115, d_svhn_loss: 0.0418, d_fake_loss: 0.0753, gen_loss_A: 1.0598, gen_loss_B: 1.4868,\n",
            "reconst_loss_A: 0.1726, recons_loss_B: 0.2200, \n",
            "Step [2570/4000], d_real_loss: 0.2506, d_mnist_loss: 0.1600, d_svhn_loss: 0.0906, d_fake_loss: 0.2810, gen_loss_A: 0.8635, gen_loss_B: 1.8830,\n",
            "reconst_loss_A: 0.1434, recons_loss_B: 0.1886, \n",
            "Step [2580/4000], d_real_loss: 0.2913, d_mnist_loss: 0.0292, d_svhn_loss: 0.2622, d_fake_loss: 0.0861, gen_loss_A: 1.0874, gen_loss_B: 1.2739,\n",
            "reconst_loss_A: 0.1617, recons_loss_B: 0.1077, \n",
            "Step [2590/4000], d_real_loss: 0.3847, d_mnist_loss: 0.1743, d_svhn_loss: 0.2104, d_fake_loss: 0.1819, gen_loss_A: 1.2045, gen_loss_B: 0.9408,\n",
            "reconst_loss_A: 0.1250, recons_loss_B: 0.1603, \n",
            "Step [2600/4000], d_real_loss: 0.0914, d_mnist_loss: 0.0304, d_svhn_loss: 0.0611, d_fake_loss: 0.1335, gen_loss_A: 1.2355, gen_loss_B: 0.7840,\n",
            "reconst_loss_A: 0.1673, recons_loss_B: 0.1057, \n",
            "saved ./samples/sample-2600-m-s.png\n",
            "saved ./samples/sample-2600-s-m.png\n",
            "Step [2610/4000], d_real_loss: 0.1107, d_mnist_loss: 0.0322, d_svhn_loss: 0.0786, d_fake_loss: 0.0326, gen_loss_A: 1.2434, gen_loss_B: 1.2469,\n",
            "reconst_loss_A: 0.2123, recons_loss_B: 0.1609, \n",
            "Step [2620/4000], d_real_loss: 0.4545, d_mnist_loss: 0.0128, d_svhn_loss: 0.4418, d_fake_loss: 0.0836, gen_loss_A: 1.1574, gen_loss_B: 1.2149,\n",
            "reconst_loss_A: 0.1216, recons_loss_B: 0.1770, \n",
            "Step [2630/4000], d_real_loss: 0.4823, d_mnist_loss: 0.0425, d_svhn_loss: 0.4398, d_fake_loss: 0.1128, gen_loss_A: 1.1948, gen_loss_B: 1.0152,\n",
            "reconst_loss_A: 0.1767, recons_loss_B: 0.1664, \n",
            "Step [2640/4000], d_real_loss: 0.2037, d_mnist_loss: 0.0354, d_svhn_loss: 0.1682, d_fake_loss: 0.1051, gen_loss_A: 1.0155, gen_loss_B: 0.9352,\n",
            "reconst_loss_A: 0.1521, recons_loss_B: 0.1099, \n",
            "Step [2650/4000], d_real_loss: 0.1423, d_mnist_loss: 0.0702, d_svhn_loss: 0.0721, d_fake_loss: 0.4187, gen_loss_A: 2.1432, gen_loss_B: 1.2834,\n",
            "reconst_loss_A: 0.1502, recons_loss_B: 0.1539, \n",
            "saved ./samples/sample-2650-m-s.png\n",
            "saved ./samples/sample-2650-s-m.png\n",
            "Step [2660/4000], d_real_loss: 0.1724, d_mnist_loss: 0.0382, d_svhn_loss: 0.1342, d_fake_loss: 0.0343, gen_loss_A: 1.0093, gen_loss_B: 1.2356,\n",
            "reconst_loss_A: 0.1395, recons_loss_B: 0.1221, \n",
            "Step [2670/4000], d_real_loss: 0.0726, d_mnist_loss: 0.0337, d_svhn_loss: 0.0390, d_fake_loss: 0.1499, gen_loss_A: 1.3484, gen_loss_B: 1.1228,\n",
            "reconst_loss_A: 0.1508, recons_loss_B: 0.1771, \n",
            "Step [2680/4000], d_real_loss: 0.0833, d_mnist_loss: 0.0349, d_svhn_loss: 0.0484, d_fake_loss: 0.3676, gen_loss_A: 1.6504, gen_loss_B: 1.2020,\n",
            "reconst_loss_A: 0.1927, recons_loss_B: 0.1745, \n",
            "Step [2690/4000], d_real_loss: 0.1986, d_mnist_loss: 0.0320, d_svhn_loss: 0.1666, d_fake_loss: 0.1259, gen_loss_A: 1.1802, gen_loss_B: 1.5052,\n",
            "reconst_loss_A: 0.1811, recons_loss_B: 0.1574, \n",
            "Step [2700/4000], d_real_loss: 0.2057, d_mnist_loss: 0.1071, d_svhn_loss: 0.0986, d_fake_loss: 0.2600, gen_loss_A: 1.3495, gen_loss_B: 1.1913,\n",
            "reconst_loss_A: 0.1633, recons_loss_B: 0.1187, \n",
            "saved ./samples/sample-2700-m-s.png\n",
            "saved ./samples/sample-2700-s-m.png\n",
            "Step [2710/4000], d_real_loss: 0.0476, d_mnist_loss: 0.0126, d_svhn_loss: 0.0351, d_fake_loss: 0.3922, gen_loss_A: 1.5671, gen_loss_B: 1.7703,\n",
            "reconst_loss_A: 0.1612, recons_loss_B: 0.1636, \n",
            "Step [2720/4000], d_real_loss: 0.2690, d_mnist_loss: 0.1371, d_svhn_loss: 0.1319, d_fake_loss: 0.0634, gen_loss_A: 1.0864, gen_loss_B: 1.2271,\n",
            "reconst_loss_A: 0.1956, recons_loss_B: 0.2297, \n",
            "Step [2730/4000], d_real_loss: 0.1220, d_mnist_loss: 0.0386, d_svhn_loss: 0.0834, d_fake_loss: 0.4058, gen_loss_A: 1.5014, gen_loss_B: 0.7130,\n",
            "reconst_loss_A: 0.1573, recons_loss_B: 0.1394, \n",
            "Step [2740/4000], d_real_loss: 0.0662, d_mnist_loss: 0.0275, d_svhn_loss: 0.0387, d_fake_loss: 0.1346, gen_loss_A: 1.2062, gen_loss_B: 1.1469,\n",
            "reconst_loss_A: 0.1796, recons_loss_B: 0.1508, \n",
            "Step [2750/4000], d_real_loss: 0.2462, d_mnist_loss: 0.0260, d_svhn_loss: 0.2202, d_fake_loss: 0.0869, gen_loss_A: 1.0529, gen_loss_B: 1.2767,\n",
            "reconst_loss_A: 0.1880, recons_loss_B: 0.2038, \n",
            "saved ./samples/sample-2750-m-s.png\n",
            "saved ./samples/sample-2750-s-m.png\n",
            "Step [2760/4000], d_real_loss: 0.2690, d_mnist_loss: 0.1833, d_svhn_loss: 0.0858, d_fake_loss: 0.0713, gen_loss_A: 1.2029, gen_loss_B: 0.9044,\n",
            "reconst_loss_A: 0.1622, recons_loss_B: 0.1578, \n",
            "Step [2770/4000], d_real_loss: 0.0868, d_mnist_loss: 0.0352, d_svhn_loss: 0.0516, d_fake_loss: 0.1962, gen_loss_A: 1.5725, gen_loss_B: 1.1345,\n",
            "reconst_loss_A: 0.1803, recons_loss_B: 0.1690, \n",
            "Step [2780/4000], d_real_loss: 0.0977, d_mnist_loss: 0.0286, d_svhn_loss: 0.0691, d_fake_loss: 0.2671, gen_loss_A: 1.5917, gen_loss_B: 0.9163,\n",
            "reconst_loss_A: 0.1582, recons_loss_B: 0.1779, \n",
            "Step [2790/4000], d_real_loss: 0.1722, d_mnist_loss: 0.0591, d_svhn_loss: 0.1132, d_fake_loss: 0.1305, gen_loss_A: 1.1190, gen_loss_B: 1.4811,\n",
            "reconst_loss_A: 0.1800, recons_loss_B: 0.1535, \n",
            "Step [2800/4000], d_real_loss: 0.0580, d_mnist_loss: 0.0123, d_svhn_loss: 0.0456, d_fake_loss: 0.1200, gen_loss_A: 1.3180, gen_loss_B: 1.2194,\n",
            "reconst_loss_A: 0.1496, recons_loss_B: 0.1479, \n",
            "saved ./samples/sample-2800-m-s.png\n",
            "saved ./samples/sample-2800-s-m.png\n",
            "Step [2810/4000], d_real_loss: 0.4388, d_mnist_loss: 0.0545, d_svhn_loss: 0.3843, d_fake_loss: 0.1016, gen_loss_A: 0.8089, gen_loss_B: 1.3436,\n",
            "reconst_loss_A: 0.1604, recons_loss_B: 0.1363, \n",
            "Step [2820/4000], d_real_loss: 0.2678, d_mnist_loss: 0.0268, d_svhn_loss: 0.2410, d_fake_loss: 0.3755, gen_loss_A: 1.5253, gen_loss_B: 1.1247,\n",
            "reconst_loss_A: 0.1508, recons_loss_B: 0.1333, \n",
            "Step [2830/4000], d_real_loss: 0.1098, d_mnist_loss: 0.0182, d_svhn_loss: 0.0916, d_fake_loss: 0.2675, gen_loss_A: 1.3513, gen_loss_B: 1.2575,\n",
            "reconst_loss_A: 0.1676, recons_loss_B: 0.1244, \n",
            "Step [2840/4000], d_real_loss: 0.1451, d_mnist_loss: 0.0230, d_svhn_loss: 0.1221, d_fake_loss: 0.0536, gen_loss_A: 1.0258, gen_loss_B: 1.0878,\n",
            "reconst_loss_A: 0.2052, recons_loss_B: 0.1430, \n",
            "Step [2850/4000], d_real_loss: 0.5253, d_mnist_loss: 0.2762, d_svhn_loss: 0.2492, d_fake_loss: 0.1593, gen_loss_A: 0.7874, gen_loss_B: 1.0244,\n",
            "reconst_loss_A: 0.1402, recons_loss_B: 0.1789, \n",
            "saved ./samples/sample-2850-m-s.png\n",
            "saved ./samples/sample-2850-s-m.png\n",
            "Step [2860/4000], d_real_loss: 0.0782, d_mnist_loss: 0.0175, d_svhn_loss: 0.0606, d_fake_loss: 0.0719, gen_loss_A: 1.3455, gen_loss_B: 1.0849,\n",
            "reconst_loss_A: 0.1577, recons_loss_B: 0.1752, \n",
            "Step [2870/4000], d_real_loss: 0.1633, d_mnist_loss: 0.0394, d_svhn_loss: 0.1239, d_fake_loss: 0.2531, gen_loss_A: 0.4732, gen_loss_B: 1.1984,\n",
            "reconst_loss_A: 0.1611, recons_loss_B: 0.1752, \n",
            "Step [2880/4000], d_real_loss: 0.0603, d_mnist_loss: 0.0164, d_svhn_loss: 0.0440, d_fake_loss: 0.1677, gen_loss_A: 1.5122, gen_loss_B: 1.5114,\n",
            "reconst_loss_A: 0.1880, recons_loss_B: 0.1545, \n",
            "Step [2890/4000], d_real_loss: 0.2728, d_mnist_loss: 0.1684, d_svhn_loss: 0.1043, d_fake_loss: 0.1662, gen_loss_A: 1.9321, gen_loss_B: 1.3198,\n",
            "reconst_loss_A: 0.1489, recons_loss_B: 0.1684, \n",
            "Step [2900/4000], d_real_loss: 0.0961, d_mnist_loss: 0.0620, d_svhn_loss: 0.0341, d_fake_loss: 0.1639, gen_loss_A: 1.4846, gen_loss_B: 0.9660,\n",
            "reconst_loss_A: 0.1804, recons_loss_B: 0.1430, \n",
            "saved ./samples/sample-2900-m-s.png\n",
            "saved ./samples/sample-2900-s-m.png\n",
            "Step [2910/4000], d_real_loss: 0.2055, d_mnist_loss: 0.0388, d_svhn_loss: 0.1666, d_fake_loss: 0.1377, gen_loss_A: 1.0602, gen_loss_B: 1.4727,\n",
            "reconst_loss_A: 0.1654, recons_loss_B: 0.1346, \n",
            "Step [2920/4000], d_real_loss: 0.3741, d_mnist_loss: 0.3298, d_svhn_loss: 0.0443, d_fake_loss: 0.3150, gen_loss_A: 1.3377, gen_loss_B: 1.1448,\n",
            "reconst_loss_A: 0.1602, recons_loss_B: 0.1851, \n",
            "Step [2930/4000], d_real_loss: 0.0755, d_mnist_loss: 0.0510, d_svhn_loss: 0.0245, d_fake_loss: 0.1470, gen_loss_A: 1.1587, gen_loss_B: 1.3854,\n",
            "reconst_loss_A: 0.1563, recons_loss_B: 0.1644, \n",
            "Step [2940/4000], d_real_loss: 0.2184, d_mnist_loss: 0.0112, d_svhn_loss: 0.2072, d_fake_loss: 0.1821, gen_loss_A: 1.2070, gen_loss_B: 1.4143,\n",
            "reconst_loss_A: 0.1238, recons_loss_B: 0.1631, \n",
            "Step [2950/4000], d_real_loss: 0.2067, d_mnist_loss: 0.0293, d_svhn_loss: 0.1774, d_fake_loss: 0.2010, gen_loss_A: 1.3595, gen_loss_B: 1.1777,\n",
            "reconst_loss_A: 0.1959, recons_loss_B: 0.1292, \n",
            "saved ./samples/sample-2950-m-s.png\n",
            "saved ./samples/sample-2950-s-m.png\n",
            "Step [2960/4000], d_real_loss: 0.2754, d_mnist_loss: 0.1835, d_svhn_loss: 0.0919, d_fake_loss: 0.0637, gen_loss_A: 1.1482, gen_loss_B: 1.0437,\n",
            "reconst_loss_A: 0.1281, recons_loss_B: 0.1107, \n",
            "Step [2970/4000], d_real_loss: 0.2319, d_mnist_loss: 0.1493, d_svhn_loss: 0.0826, d_fake_loss: 0.1615, gen_loss_A: 0.6937, gen_loss_B: 0.9581,\n",
            "reconst_loss_A: 0.1357, recons_loss_B: 0.1180, \n",
            "Step [2980/4000], d_real_loss: 0.1508, d_mnist_loss: 0.0321, d_svhn_loss: 0.1187, d_fake_loss: 0.1613, gen_loss_A: 1.0783, gen_loss_B: 1.4746,\n",
            "reconst_loss_A: 0.1270, recons_loss_B: 0.1817, \n",
            "Step [2990/4000], d_real_loss: 0.1318, d_mnist_loss: 0.0572, d_svhn_loss: 0.0746, d_fake_loss: 0.1281, gen_loss_A: 1.0235, gen_loss_B: 1.6135,\n",
            "reconst_loss_A: 0.1619, recons_loss_B: 0.1360, \n",
            "Step [3000/4000], d_real_loss: 0.1354, d_mnist_loss: 0.0730, d_svhn_loss: 0.0624, d_fake_loss: 0.3329, gen_loss_A: 1.2739, gen_loss_B: 1.3791,\n",
            "reconst_loss_A: 0.1572, recons_loss_B: 0.1100, \n",
            "saved ./samples/sample-3000-m-s.png\n",
            "saved ./samples/sample-3000-s-m.png\n",
            "Step [3010/4000], d_real_loss: 0.1930, d_mnist_loss: 0.1606, d_svhn_loss: 0.0324, d_fake_loss: 0.2700, gen_loss_A: 1.7958, gen_loss_B: 1.1132,\n",
            "reconst_loss_A: 0.1580, recons_loss_B: 0.1698, \n",
            "Step [3020/4000], d_real_loss: 0.2561, d_mnist_loss: 0.1368, d_svhn_loss: 0.1193, d_fake_loss: 0.0832, gen_loss_A: 1.0959, gen_loss_B: 1.5029,\n",
            "reconst_loss_A: 0.1577, recons_loss_B: 0.1613, \n",
            "Step [3030/4000], d_real_loss: 0.0356, d_mnist_loss: 0.0145, d_svhn_loss: 0.0211, d_fake_loss: 0.2203, gen_loss_A: 1.2759, gen_loss_B: 0.9855,\n",
            "reconst_loss_A: 0.1662, recons_loss_B: 0.1304, \n",
            "Step [3040/4000], d_real_loss: 0.0810, d_mnist_loss: 0.0116, d_svhn_loss: 0.0694, d_fake_loss: 0.0937, gen_loss_A: 1.2620, gen_loss_B: 1.1237,\n",
            "reconst_loss_A: 0.1498, recons_loss_B: 0.1164, \n",
            "Step [3050/4000], d_real_loss: 0.0883, d_mnist_loss: 0.0298, d_svhn_loss: 0.0585, d_fake_loss: 0.1725, gen_loss_A: 1.3741, gen_loss_B: 1.2847,\n",
            "reconst_loss_A: 0.1854, recons_loss_B: 0.1707, \n",
            "saved ./samples/sample-3050-m-s.png\n",
            "saved ./samples/sample-3050-s-m.png\n",
            "Step [3060/4000], d_real_loss: 0.0389, d_mnist_loss: 0.0199, d_svhn_loss: 0.0189, d_fake_loss: 0.0511, gen_loss_A: 1.1626, gen_loss_B: 1.1610,\n",
            "reconst_loss_A: 0.2000, recons_loss_B: 0.1284, \n",
            "Step [3070/4000], d_real_loss: 0.1695, d_mnist_loss: 0.0758, d_svhn_loss: 0.0937, d_fake_loss: 0.1359, gen_loss_A: 1.4506, gen_loss_B: 1.2154,\n",
            "reconst_loss_A: 0.1855, recons_loss_B: 0.1743, \n",
            "Step [3080/4000], d_real_loss: 0.1055, d_mnist_loss: 0.0738, d_svhn_loss: 0.0317, d_fake_loss: 0.7011, gen_loss_A: 1.3451, gen_loss_B: 1.5194,\n",
            "reconst_loss_A: 0.1566, recons_loss_B: 0.1584, \n",
            "Step [3090/4000], d_real_loss: 0.2024, d_mnist_loss: 0.1170, d_svhn_loss: 0.0854, d_fake_loss: 0.2424, gen_loss_A: 1.6429, gen_loss_B: 1.0414,\n",
            "reconst_loss_A: 0.1695, recons_loss_B: 0.1680, \n",
            "Step [3100/4000], d_real_loss: 0.3696, d_mnist_loss: 0.2944, d_svhn_loss: 0.0752, d_fake_loss: 0.3147, gen_loss_A: 1.4722, gen_loss_B: 1.0336,\n",
            "reconst_loss_A: 0.1352, recons_loss_B: 0.1248, \n",
            "saved ./samples/sample-3100-m-s.png\n",
            "saved ./samples/sample-3100-s-m.png\n",
            "Step [3110/4000], d_real_loss: 0.1407, d_mnist_loss: 0.0287, d_svhn_loss: 0.1119, d_fake_loss: 0.1623, gen_loss_A: 1.2227, gen_loss_B: 1.5527,\n",
            "reconst_loss_A: 0.2057, recons_loss_B: 0.1636, \n",
            "Step [3120/4000], d_real_loss: 0.2989, d_mnist_loss: 0.0114, d_svhn_loss: 0.2876, d_fake_loss: 0.2276, gen_loss_A: 1.2492, gen_loss_B: 1.4191,\n",
            "reconst_loss_A: 0.1285, recons_loss_B: 0.1501, \n",
            "Step [3130/4000], d_real_loss: 0.1781, d_mnist_loss: 0.0815, d_svhn_loss: 0.0966, d_fake_loss: 0.3967, gen_loss_A: 1.6072, gen_loss_B: 1.4472,\n",
            "reconst_loss_A: 0.1303, recons_loss_B: 0.1690, \n",
            "Step [3140/4000], d_real_loss: 0.1110, d_mnist_loss: 0.0629, d_svhn_loss: 0.0481, d_fake_loss: 0.1240, gen_loss_A: 1.3615, gen_loss_B: 1.3544,\n",
            "reconst_loss_A: 0.1562, recons_loss_B: 0.1539, \n",
            "Step [3150/4000], d_real_loss: 0.1457, d_mnist_loss: 0.0617, d_svhn_loss: 0.0841, d_fake_loss: 0.0533, gen_loss_A: 1.1799, gen_loss_B: 1.0077,\n",
            "reconst_loss_A: 0.1578, recons_loss_B: 0.2050, \n",
            "saved ./samples/sample-3150-m-s.png\n",
            "saved ./samples/sample-3150-s-m.png\n",
            "Step [3160/4000], d_real_loss: 0.0504, d_mnist_loss: 0.0209, d_svhn_loss: 0.0295, d_fake_loss: 0.2430, gen_loss_A: 1.5704, gen_loss_B: 1.2124,\n",
            "reconst_loss_A: 0.1643, recons_loss_B: 0.1578, \n",
            "Step [3170/4000], d_real_loss: 0.0972, d_mnist_loss: 0.0291, d_svhn_loss: 0.0681, d_fake_loss: 0.1253, gen_loss_A: 1.4857, gen_loss_B: 1.3401,\n",
            "reconst_loss_A: 0.2032, recons_loss_B: 0.1408, \n",
            "Step [3180/4000], d_real_loss: 0.7497, d_mnist_loss: 0.2063, d_svhn_loss: 0.5434, d_fake_loss: 0.1799, gen_loss_A: 0.5638, gen_loss_B: 0.7763,\n",
            "reconst_loss_A: 0.1662, recons_loss_B: 0.1483, \n",
            "Step [3190/4000], d_real_loss: 0.4589, d_mnist_loss: 0.0447, d_svhn_loss: 0.4142, d_fake_loss: 0.0659, gen_loss_A: 1.0014, gen_loss_B: 1.3385,\n",
            "reconst_loss_A: 0.1844, recons_loss_B: 0.1863, \n",
            "Step [3200/4000], d_real_loss: 0.2252, d_mnist_loss: 0.0855, d_svhn_loss: 0.1397, d_fake_loss: 0.2646, gen_loss_A: 1.8713, gen_loss_B: 1.2914,\n",
            "reconst_loss_A: 0.2020, recons_loss_B: 0.1331, \n",
            "saved ./samples/sample-3200-m-s.png\n",
            "saved ./samples/sample-3200-s-m.png\n",
            "Step [3210/4000], d_real_loss: 0.1104, d_mnist_loss: 0.0674, d_svhn_loss: 0.0430, d_fake_loss: 0.1083, gen_loss_A: 1.6574, gen_loss_B: 1.0452,\n",
            "reconst_loss_A: 0.2050, recons_loss_B: 0.1878, \n",
            "Step [3220/4000], d_real_loss: 0.3356, d_mnist_loss: 0.0928, d_svhn_loss: 0.2428, d_fake_loss: 0.2348, gen_loss_A: 1.2354, gen_loss_B: 1.1764,\n",
            "reconst_loss_A: 0.1440, recons_loss_B: 0.1510, \n",
            "Step [3230/4000], d_real_loss: 0.1726, d_mnist_loss: 0.0285, d_svhn_loss: 0.1441, d_fake_loss: 0.1586, gen_loss_A: 1.2993, gen_loss_B: 1.0289,\n",
            "reconst_loss_A: 0.1616, recons_loss_B: 0.1408, \n",
            "Step [3240/4000], d_real_loss: 0.1309, d_mnist_loss: 0.0488, d_svhn_loss: 0.0822, d_fake_loss: 0.1723, gen_loss_A: 1.4840, gen_loss_B: 1.1638,\n",
            "reconst_loss_A: 0.2070, recons_loss_B: 0.1989, \n",
            "Step [3250/4000], d_real_loss: 0.2063, d_mnist_loss: 0.1312, d_svhn_loss: 0.0751, d_fake_loss: 0.0581, gen_loss_A: 1.2539, gen_loss_B: 0.9443,\n",
            "reconst_loss_A: 0.1761, recons_loss_B: 0.1273, \n",
            "saved ./samples/sample-3250-m-s.png\n",
            "saved ./samples/sample-3250-s-m.png\n",
            "Step [3260/4000], d_real_loss: 0.0605, d_mnist_loss: 0.0311, d_svhn_loss: 0.0294, d_fake_loss: 0.2525, gen_loss_A: 1.8389, gen_loss_B: 0.8588,\n",
            "reconst_loss_A: 0.1559, recons_loss_B: 0.1187, \n",
            "Step [3270/4000], d_real_loss: 0.1080, d_mnist_loss: 0.0198, d_svhn_loss: 0.0882, d_fake_loss: 0.2302, gen_loss_A: 1.5861, gen_loss_B: 0.8239,\n",
            "reconst_loss_A: 0.2007, recons_loss_B: 0.1409, \n",
            "Step [3280/4000], d_real_loss: 0.1054, d_mnist_loss: 0.0296, d_svhn_loss: 0.0758, d_fake_loss: 0.1400, gen_loss_A: 1.0892, gen_loss_B: 1.4786,\n",
            "reconst_loss_A: 0.1909, recons_loss_B: 0.1156, \n",
            "Step [3290/4000], d_real_loss: 0.0809, d_mnist_loss: 0.0455, d_svhn_loss: 0.0355, d_fake_loss: 0.0881, gen_loss_A: 1.4552, gen_loss_B: 1.0779,\n",
            "reconst_loss_A: 0.1758, recons_loss_B: 0.1805, \n",
            "Step [3300/4000], d_real_loss: 0.1653, d_mnist_loss: 0.0827, d_svhn_loss: 0.0826, d_fake_loss: 1.1238, gen_loss_A: 2.0111, gen_loss_B: 0.9379,\n",
            "reconst_loss_A: 0.2039, recons_loss_B: 0.1893, \n",
            "saved ./samples/sample-3300-m-s.png\n",
            "saved ./samples/sample-3300-s-m.png\n",
            "Step [3310/4000], d_real_loss: 0.1183, d_mnist_loss: 0.0713, d_svhn_loss: 0.0470, d_fake_loss: 0.4763, gen_loss_A: 1.4782, gen_loss_B: 1.1467,\n",
            "reconst_loss_A: 0.1250, recons_loss_B: 0.1272, \n",
            "Step [3320/4000], d_real_loss: 0.1653, d_mnist_loss: 0.0865, d_svhn_loss: 0.0788, d_fake_loss: 0.0844, gen_loss_A: 1.2212, gen_loss_B: 1.1062,\n",
            "reconst_loss_A: 0.1397, recons_loss_B: 0.1320, \n",
            "Step [3330/4000], d_real_loss: 0.1866, d_mnist_loss: 0.1650, d_svhn_loss: 0.0216, d_fake_loss: 0.1648, gen_loss_A: 1.5060, gen_loss_B: 1.1202,\n",
            "reconst_loss_A: 0.1513, recons_loss_B: 0.1597, \n",
            "Step [3340/4000], d_real_loss: 0.1953, d_mnist_loss: 0.1123, d_svhn_loss: 0.0831, d_fake_loss: 0.0724, gen_loss_A: 1.1248, gen_loss_B: 1.2623,\n",
            "reconst_loss_A: 0.1565, recons_loss_B: 0.1985, \n",
            "Step [3350/4000], d_real_loss: 0.0586, d_mnist_loss: 0.0221, d_svhn_loss: 0.0364, d_fake_loss: 0.2464, gen_loss_A: 1.9016, gen_loss_B: 1.2853,\n",
            "reconst_loss_A: 0.1541, recons_loss_B: 0.1419, \n",
            "saved ./samples/sample-3350-m-s.png\n",
            "saved ./samples/sample-3350-s-m.png\n",
            "Step [3360/4000], d_real_loss: 0.0599, d_mnist_loss: 0.0177, d_svhn_loss: 0.0422, d_fake_loss: 0.0488, gen_loss_A: 1.1773, gen_loss_B: 1.1003,\n",
            "reconst_loss_A: 0.1444, recons_loss_B: 0.1722, \n",
            "Step [3370/4000], d_real_loss: 0.3166, d_mnist_loss: 0.2430, d_svhn_loss: 0.0736, d_fake_loss: 0.1286, gen_loss_A: 1.2116, gen_loss_B: 1.0755,\n",
            "reconst_loss_A: 0.1820, recons_loss_B: 0.1271, \n",
            "Step [3380/4000], d_real_loss: 0.4312, d_mnist_loss: 0.2498, d_svhn_loss: 0.1815, d_fake_loss: 0.1664, gen_loss_A: 1.1727, gen_loss_B: 0.9324,\n",
            "reconst_loss_A: 0.1707, recons_loss_B: 0.1053, \n",
            "Step [3390/4000], d_real_loss: 0.1465, d_mnist_loss: 0.0297, d_svhn_loss: 0.1168, d_fake_loss: 0.1619, gen_loss_A: 1.3684, gen_loss_B: 1.2904,\n",
            "reconst_loss_A: 0.1751, recons_loss_B: 0.1579, \n",
            "Step [3400/4000], d_real_loss: 0.1258, d_mnist_loss: 0.0433, d_svhn_loss: 0.0825, d_fake_loss: 0.1271, gen_loss_A: 1.4841, gen_loss_B: 1.0032,\n",
            "reconst_loss_A: 0.1501, recons_loss_B: 0.1465, \n",
            "saved ./samples/sample-3400-m-s.png\n",
            "saved ./samples/sample-3400-s-m.png\n",
            "Step [3410/4000], d_real_loss: 0.0751, d_mnist_loss: 0.0137, d_svhn_loss: 0.0614, d_fake_loss: 0.1078, gen_loss_A: 1.3317, gen_loss_B: 1.0591,\n",
            "reconst_loss_A: 0.1838, recons_loss_B: 0.1174, \n",
            "Step [3420/4000], d_real_loss: 0.0660, d_mnist_loss: 0.0350, d_svhn_loss: 0.0310, d_fake_loss: 0.2958, gen_loss_A: 1.6899, gen_loss_B: 1.5590,\n",
            "reconst_loss_A: 0.1613, recons_loss_B: 0.1354, \n",
            "Step [3430/4000], d_real_loss: 0.3883, d_mnist_loss: 0.0761, d_svhn_loss: 0.3122, d_fake_loss: 0.2366, gen_loss_A: 1.3284, gen_loss_B: 1.1627,\n",
            "reconst_loss_A: 0.2009, recons_loss_B: 0.1237, \n",
            "Step [3440/4000], d_real_loss: 0.3305, d_mnist_loss: 0.0195, d_svhn_loss: 0.3111, d_fake_loss: 0.1285, gen_loss_A: 0.8949, gen_loss_B: 1.4033,\n",
            "reconst_loss_A: 0.1628, recons_loss_B: 0.1307, \n",
            "Step [3450/4000], d_real_loss: 0.1431, d_mnist_loss: 0.0448, d_svhn_loss: 0.0982, d_fake_loss: 0.1075, gen_loss_A: 0.9575, gen_loss_B: 1.1435,\n",
            "reconst_loss_A: 0.1899, recons_loss_B: 0.1812, \n",
            "saved ./samples/sample-3450-m-s.png\n",
            "saved ./samples/sample-3450-s-m.png\n",
            "Step [3460/4000], d_real_loss: 0.2312, d_mnist_loss: 0.1707, d_svhn_loss: 0.0605, d_fake_loss: 0.3260, gen_loss_A: 1.9335, gen_loss_B: 1.4050,\n",
            "reconst_loss_A: 0.1733, recons_loss_B: 0.1633, \n",
            "Step [3470/4000], d_real_loss: 0.1295, d_mnist_loss: 0.0701, d_svhn_loss: 0.0594, d_fake_loss: 0.0653, gen_loss_A: 1.1665, gen_loss_B: 1.6652,\n",
            "reconst_loss_A: 0.1286, recons_loss_B: 0.1432, \n",
            "Step [3480/4000], d_real_loss: 0.1201, d_mnist_loss: 0.0639, d_svhn_loss: 0.0562, d_fake_loss: 0.1463, gen_loss_A: 1.4905, gen_loss_B: 0.9571,\n",
            "reconst_loss_A: 0.1667, recons_loss_B: 0.1629, \n",
            "Step [3490/4000], d_real_loss: 0.1583, d_mnist_loss: 0.0606, d_svhn_loss: 0.0977, d_fake_loss: 0.1400, gen_loss_A: 1.4144, gen_loss_B: 1.4826,\n",
            "reconst_loss_A: 0.2457, recons_loss_B: 0.1439, \n",
            "Step [3500/4000], d_real_loss: 0.0481, d_mnist_loss: 0.0195, d_svhn_loss: 0.0286, d_fake_loss: 0.1322, gen_loss_A: 1.8181, gen_loss_B: 1.2576,\n",
            "reconst_loss_A: 0.1977, recons_loss_B: 0.1904, \n",
            "saved ./samples/sample-3500-m-s.png\n",
            "saved ./samples/sample-3500-s-m.png\n",
            "Step [3510/4000], d_real_loss: 0.0526, d_mnist_loss: 0.0183, d_svhn_loss: 0.0343, d_fake_loss: 0.0577, gen_loss_A: 1.1469, gen_loss_B: 0.9557,\n",
            "reconst_loss_A: 0.1659, recons_loss_B: 0.1255, \n",
            "Step [3520/4000], d_real_loss: 0.1004, d_mnist_loss: 0.0278, d_svhn_loss: 0.0726, d_fake_loss: 0.1184, gen_loss_A: 1.0174, gen_loss_B: 1.1988,\n",
            "reconst_loss_A: 0.1659, recons_loss_B: 0.1758, \n",
            "Step [3530/4000], d_real_loss: 0.1198, d_mnist_loss: 0.0473, d_svhn_loss: 0.0725, d_fake_loss: 0.2345, gen_loss_A: 1.4588, gen_loss_B: 1.2490,\n",
            "reconst_loss_A: 0.1766, recons_loss_B: 0.1105, \n",
            "Step [3540/4000], d_real_loss: 0.0794, d_mnist_loss: 0.0176, d_svhn_loss: 0.0618, d_fake_loss: 0.2039, gen_loss_A: 1.7358, gen_loss_B: 1.4133,\n",
            "reconst_loss_A: 0.2033, recons_loss_B: 0.1748, \n",
            "Step [3550/4000], d_real_loss: 0.0892, d_mnist_loss: 0.0544, d_svhn_loss: 0.0349, d_fake_loss: 0.1825, gen_loss_A: 1.6841, gen_loss_B: 1.2061,\n",
            "reconst_loss_A: 0.1809, recons_loss_B: 0.1707, \n",
            "saved ./samples/sample-3550-m-s.png\n",
            "saved ./samples/sample-3550-s-m.png\n",
            "Step [3560/4000], d_real_loss: 0.0815, d_mnist_loss: 0.0339, d_svhn_loss: 0.0477, d_fake_loss: 0.0639, gen_loss_A: 1.1734, gen_loss_B: 1.0667,\n",
            "reconst_loss_A: 0.1864, recons_loss_B: 0.1443, \n",
            "Step [3570/4000], d_real_loss: 0.2761, d_mnist_loss: 0.0969, d_svhn_loss: 0.1793, d_fake_loss: 0.0587, gen_loss_A: 0.8614, gen_loss_B: 1.1459,\n",
            "reconst_loss_A: 0.1674, recons_loss_B: 0.1835, \n",
            "Step [3580/4000], d_real_loss: 0.4771, d_mnist_loss: 0.1820, d_svhn_loss: 0.2951, d_fake_loss: 0.1122, gen_loss_A: 1.0673, gen_loss_B: 1.0616,\n",
            "reconst_loss_A: 0.1983, recons_loss_B: 0.1427, \n",
            "Step [3590/4000], d_real_loss: 0.0829, d_mnist_loss: 0.0351, d_svhn_loss: 0.0478, d_fake_loss: 0.0711, gen_loss_A: 1.3032, gen_loss_B: 1.5056,\n",
            "reconst_loss_A: 0.1459, recons_loss_B: 0.1812, \n",
            "Step [3600/4000], d_real_loss: 0.0562, d_mnist_loss: 0.0188, d_svhn_loss: 0.0374, d_fake_loss: 0.1359, gen_loss_A: 1.2118, gen_loss_B: 1.4421,\n",
            "reconst_loss_A: 0.1921, recons_loss_B: 0.1704, \n",
            "saved ./samples/sample-3600-m-s.png\n",
            "saved ./samples/sample-3600-s-m.png\n",
            "Step [3610/4000], d_real_loss: 0.1136, d_mnist_loss: 0.0370, d_svhn_loss: 0.0766, d_fake_loss: 0.1419, gen_loss_A: 1.3883, gen_loss_B: 0.9566,\n",
            "reconst_loss_A: 0.1746, recons_loss_B: 0.1627, \n",
            "Step [3620/4000], d_real_loss: 0.1124, d_mnist_loss: 0.0607, d_svhn_loss: 0.0518, d_fake_loss: 0.0849, gen_loss_A: 1.4825, gen_loss_B: 1.1936,\n",
            "reconst_loss_A: 0.1537, recons_loss_B: 0.1946, \n",
            "Step [3630/4000], d_real_loss: 0.1217, d_mnist_loss: 0.0357, d_svhn_loss: 0.0860, d_fake_loss: 0.1732, gen_loss_A: 1.4352, gen_loss_B: 1.0090,\n",
            "reconst_loss_A: 0.1466, recons_loss_B: 0.1386, \n",
            "Step [3640/4000], d_real_loss: 0.0540, d_mnist_loss: 0.0170, d_svhn_loss: 0.0370, d_fake_loss: 0.5172, gen_loss_A: 2.0756, gen_loss_B: 1.4674,\n",
            "reconst_loss_A: 0.2219, recons_loss_B: 0.1376, \n",
            "Step [3650/4000], d_real_loss: 0.1994, d_mnist_loss: 0.1309, d_svhn_loss: 0.0685, d_fake_loss: 0.2115, gen_loss_A: 1.6205, gen_loss_B: 1.3713,\n",
            "reconst_loss_A: 0.1923, recons_loss_B: 0.1411, \n",
            "saved ./samples/sample-3650-m-s.png\n",
            "saved ./samples/sample-3650-s-m.png\n",
            "Step [3660/4000], d_real_loss: 0.2878, d_mnist_loss: 0.1805, d_svhn_loss: 0.1073, d_fake_loss: 0.1035, gen_loss_A: 1.2315, gen_loss_B: 0.9172,\n",
            "reconst_loss_A: 0.2059, recons_loss_B: 0.1209, \n",
            "Step [3670/4000], d_real_loss: 0.2077, d_mnist_loss: 0.0184, d_svhn_loss: 0.1893, d_fake_loss: 0.1284, gen_loss_A: 0.8855, gen_loss_B: 1.4495,\n",
            "reconst_loss_A: 0.1769, recons_loss_B: 0.1561, \n",
            "Step [3680/4000], d_real_loss: 0.1218, d_mnist_loss: 0.0831, d_svhn_loss: 0.0386, d_fake_loss: 0.1465, gen_loss_A: 1.6866, gen_loss_B: 1.0473,\n",
            "reconst_loss_A: 0.2061, recons_loss_B: 0.1949, \n",
            "Step [3690/4000], d_real_loss: 0.0595, d_mnist_loss: 0.0312, d_svhn_loss: 0.0283, d_fake_loss: 0.1705, gen_loss_A: 1.6991, gen_loss_B: 1.1436,\n",
            "reconst_loss_A: 0.1598, recons_loss_B: 0.1446, \n",
            "Step [3700/4000], d_real_loss: 0.3593, d_mnist_loss: 0.1593, d_svhn_loss: 0.1999, d_fake_loss: 0.1144, gen_loss_A: 1.2428, gen_loss_B: 1.1256,\n",
            "reconst_loss_A: 0.1404, recons_loss_B: 0.1392, \n",
            "saved ./samples/sample-3700-m-s.png\n",
            "saved ./samples/sample-3700-s-m.png\n",
            "Step [3710/4000], d_real_loss: 0.1608, d_mnist_loss: 0.0124, d_svhn_loss: 0.1484, d_fake_loss: 0.0760, gen_loss_A: 1.1331, gen_loss_B: 0.8735,\n",
            "reconst_loss_A: 0.1585, recons_loss_B: 0.1063, \n",
            "Step [3720/4000], d_real_loss: 0.0488, d_mnist_loss: 0.0134, d_svhn_loss: 0.0354, d_fake_loss: 0.0795, gen_loss_A: 1.2426, gen_loss_B: 0.9387,\n",
            "reconst_loss_A: 0.1930, recons_loss_B: 0.1693, \n",
            "Step [3730/4000], d_real_loss: 0.0460, d_mnist_loss: 0.0116, d_svhn_loss: 0.0344, d_fake_loss: 0.1223, gen_loss_A: 1.4098, gen_loss_B: 1.5535,\n",
            "reconst_loss_A: 0.1814, recons_loss_B: 0.1378, \n",
            "Step [3740/4000], d_real_loss: 0.1404, d_mnist_loss: 0.0962, d_svhn_loss: 0.0443, d_fake_loss: 0.0948, gen_loss_A: 1.3091, gen_loss_B: 1.1911,\n",
            "reconst_loss_A: 0.1941, recons_loss_B: 0.1155, \n",
            "Step [3750/4000], d_real_loss: 0.2965, d_mnist_loss: 0.0751, d_svhn_loss: 0.2214, d_fake_loss: 0.4112, gen_loss_A: 1.5427, gen_loss_B: 1.2631,\n",
            "reconst_loss_A: 0.1896, recons_loss_B: 0.1271, \n",
            "saved ./samples/sample-3750-m-s.png\n",
            "saved ./samples/sample-3750-s-m.png\n",
            "Step [3760/4000], d_real_loss: 0.1273, d_mnist_loss: 0.0755, d_svhn_loss: 0.0518, d_fake_loss: 0.2129, gen_loss_A: 1.5560, gen_loss_B: 1.3735,\n",
            "reconst_loss_A: 0.1731, recons_loss_B: 0.1726, \n",
            "Step [3770/4000], d_real_loss: 0.1889, d_mnist_loss: 0.0075, d_svhn_loss: 0.1814, d_fake_loss: 0.0370, gen_loss_A: 1.0720, gen_loss_B: 1.2856,\n",
            "reconst_loss_A: 0.1646, recons_loss_B: 0.1827, \n",
            "Step [3780/4000], d_real_loss: 0.1575, d_mnist_loss: 0.0298, d_svhn_loss: 0.1277, d_fake_loss: 0.2024, gen_loss_A: 1.5063, gen_loss_B: 1.3756,\n",
            "reconst_loss_A: 0.1758, recons_loss_B: 0.1046, \n",
            "Step [3790/4000], d_real_loss: 0.1292, d_mnist_loss: 0.0893, d_svhn_loss: 0.0400, d_fake_loss: 0.3111, gen_loss_A: 1.3701, gen_loss_B: 1.3305,\n",
            "reconst_loss_A: 0.1767, recons_loss_B: 0.1767, \n",
            "Step [3800/4000], d_real_loss: 0.5204, d_mnist_loss: 0.0958, d_svhn_loss: 0.4246, d_fake_loss: 0.1694, gen_loss_A: 1.4125, gen_loss_B: 0.9537,\n",
            "reconst_loss_A: 0.1995, recons_loss_B: 0.2135, \n",
            "saved ./samples/sample-3800-m-s.png\n",
            "saved ./samples/sample-3800-s-m.png\n",
            "Step [3810/4000], d_real_loss: 0.1976, d_mnist_loss: 0.0702, d_svhn_loss: 0.1274, d_fake_loss: 0.4743, gen_loss_A: 1.4884, gen_loss_B: 1.2310,\n",
            "reconst_loss_A: 0.1355, recons_loss_B: 0.1753, \n",
            "Step [3820/4000], d_real_loss: 0.0608, d_mnist_loss: 0.0151, d_svhn_loss: 0.0457, d_fake_loss: 0.1805, gen_loss_A: 1.6837, gen_loss_B: 1.3078,\n",
            "reconst_loss_A: 0.1781, recons_loss_B: 0.2103, \n",
            "Step [3830/4000], d_real_loss: 0.0965, d_mnist_loss: 0.0314, d_svhn_loss: 0.0651, d_fake_loss: 0.0349, gen_loss_A: 1.2421, gen_loss_B: 1.2467,\n",
            "reconst_loss_A: 0.2000, recons_loss_B: 0.1909, \n",
            "Step [3840/4000], d_real_loss: 0.0722, d_mnist_loss: 0.0121, d_svhn_loss: 0.0601, d_fake_loss: 0.1216, gen_loss_A: 1.9483, gen_loss_B: 1.1245,\n",
            "reconst_loss_A: 0.1831, recons_loss_B: 0.1774, \n",
            "Step [3850/4000], d_real_loss: 0.2366, d_mnist_loss: 0.2064, d_svhn_loss: 0.0302, d_fake_loss: 0.3196, gen_loss_A: 1.9877, gen_loss_B: 1.2676,\n",
            "reconst_loss_A: 0.1742, recons_loss_B: 0.1456, \n",
            "saved ./samples/sample-3850-m-s.png\n",
            "saved ./samples/sample-3850-s-m.png\n",
            "Step [3860/4000], d_real_loss: 0.3096, d_mnist_loss: 0.2632, d_svhn_loss: 0.0464, d_fake_loss: 0.0444, gen_loss_A: 1.2129, gen_loss_B: 0.8784,\n",
            "reconst_loss_A: 0.1954, recons_loss_B: 0.1528, \n",
            "Step [3870/4000], d_real_loss: 0.2832, d_mnist_loss: 0.0263, d_svhn_loss: 0.2569, d_fake_loss: 0.0613, gen_loss_A: 1.2137, gen_loss_B: 1.1238,\n",
            "reconst_loss_A: 0.2360, recons_loss_B: 0.1362, \n",
            "Step [3880/4000], d_real_loss: 0.0514, d_mnist_loss: 0.0185, d_svhn_loss: 0.0329, d_fake_loss: 0.0614, gen_loss_A: 1.4185, gen_loss_B: 1.1974,\n",
            "reconst_loss_A: 0.1697, recons_loss_B: 0.1267, \n",
            "Step [3890/4000], d_real_loss: 0.1695, d_mnist_loss: 0.0456, d_svhn_loss: 0.1239, d_fake_loss: 0.0792, gen_loss_A: 0.9080, gen_loss_B: 1.2339,\n",
            "reconst_loss_A: 0.1424, recons_loss_B: 0.1340, \n",
            "Step [3900/4000], d_real_loss: 0.1047, d_mnist_loss: 0.0684, d_svhn_loss: 0.0363, d_fake_loss: 0.1169, gen_loss_A: 1.2959, gen_loss_B: 1.2653,\n",
            "reconst_loss_A: 0.1435, recons_loss_B: 0.1061, \n",
            "saved ./samples/sample-3900-m-s.png\n",
            "saved ./samples/sample-3900-s-m.png\n",
            "Step [3910/4000], d_real_loss: 0.2762, d_mnist_loss: 0.2379, d_svhn_loss: 0.0382, d_fake_loss: 0.2235, gen_loss_A: 1.2187, gen_loss_B: 1.3694,\n",
            "reconst_loss_A: 0.2403, recons_loss_B: 0.1555, \n",
            "Step [3920/4000], d_real_loss: 0.1314, d_mnist_loss: 0.0539, d_svhn_loss: 0.0775, d_fake_loss: 0.7738, gen_loss_A: 2.1757, gen_loss_B: 1.0459,\n",
            "reconst_loss_A: 0.1574, recons_loss_B: 0.1307, \n",
            "Step [3930/4000], d_real_loss: 0.1192, d_mnist_loss: 0.0640, d_svhn_loss: 0.0552, d_fake_loss: 0.2247, gen_loss_A: 1.6186, gen_loss_B: 1.3839,\n",
            "reconst_loss_A: 0.1992, recons_loss_B: 0.1401, \n",
            "Step [3940/4000], d_real_loss: 0.0727, d_mnist_loss: 0.0165, d_svhn_loss: 0.0562, d_fake_loss: 0.0740, gen_loss_A: 1.3793, gen_loss_B: 1.2470,\n",
            "reconst_loss_A: 0.1857, recons_loss_B: 0.1961, \n",
            "Step [3950/4000], d_real_loss: 0.0741, d_mnist_loss: 0.0102, d_svhn_loss: 0.0639, d_fake_loss: 0.3960, gen_loss_A: 2.3895, gen_loss_B: 1.0263,\n",
            "reconst_loss_A: 0.1994, recons_loss_B: 0.1544, \n",
            "saved ./samples/sample-3950-m-s.png\n",
            "saved ./samples/sample-3950-s-m.png\n",
            "Step [3960/4000], d_real_loss: 0.1176, d_mnist_loss: 0.0528, d_svhn_loss: 0.0649, d_fake_loss: 0.0885, gen_loss_A: 1.2098, gen_loss_B: 1.6181,\n",
            "reconst_loss_A: 0.1562, recons_loss_B: 0.1854, \n",
            "Step [3970/4000], d_real_loss: 0.1033, d_mnist_loss: 0.0143, d_svhn_loss: 0.0890, d_fake_loss: 0.1324, gen_loss_A: 1.1565, gen_loss_B: 1.5140,\n",
            "reconst_loss_A: 0.1457, recons_loss_B: 0.1614, \n",
            "Step [3980/4000], d_real_loss: 0.0922, d_mnist_loss: 0.0286, d_svhn_loss: 0.0635, d_fake_loss: 0.1418, gen_loss_A: 1.3593, gen_loss_B: 1.0991,\n",
            "reconst_loss_A: 0.1729, recons_loss_B: 0.1253, \n",
            "Step [3990/4000], d_real_loss: 0.2835, d_mnist_loss: 0.2509, d_svhn_loss: 0.0327, d_fake_loss: 0.1952, gen_loss_A: 1.3095, gen_loss_B: 0.9587,\n",
            "reconst_loss_A: 0.1451, recons_loss_B: 0.1359, \n",
            "Step [4000/4000], d_real_loss: 0.1337, d_mnist_loss: 0.0112, d_svhn_loss: 0.1226, d_fake_loss: 0.1193, gen_loss_A: 1.2834, gen_loss_B: 1.2624,\n",
            "reconst_loss_A: 0.1512, recons_loss_B: 0.1225, \n",
            "saved ./samples/sample-4000-m-s.png\n",
            "saved ./samples/sample-4000-s-m.png\n"
          ]
        }
      ]
    }
  ]
}