{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak-hannou/compsci-4ml3/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dga32YQxm-vV"
      },
      "outputs": [],
      "source": [
        "import torch  # Core PyTorch library for tensor operations\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2  # Datasets and transformations for computer vision\n",
        "import torch.nn as nn  # Neural network components\n",
        "import torch.optim as optim  # Optimization algorithms\n",
        "import numpy as np  # Numerical operations\n",
        "import matplotlib.pyplot as plt  # Plotting\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, Subset, TensorDataset  # Data handling utilities\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 #\n",
        "learning_rate = 0.001      # Learning rate for optimizer\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "jGLOKUnUwYwo"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
        "cifar100_std = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "    v2.RandomHorizontalFlip(),\n",
        "    # v2.RandomVerticalFlip(),\n",
        "    # v2.RandomZoomOut(),\n",
        "    v2.RandomRotation(15),\n",
        "    # v2.RandomGrayscale(),\n",
        "    # v2.RandomResizedCrop(32),\n",
        "      v2.ToTensor(),\n",
        "      v2.Normalize(cifar100_mean, cifar100_std),\n",
        "      ###### Add your transformations here ########\n",
        "])\n",
        "test_transform = v2.Compose([\n",
        "      v2.ToTensor(),\n",
        "      v2.Normalize(cifar100_mean, cifar100_std),\n",
        "      ###### Add your transformations here ########\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR100(\n",
        "    root='./data',       # Change this path if needed\n",
        "    train=True,          # Set to True to download the training set\n",
        "    download=True,       # Set to True to download if not already downloaded\n",
        "    transform=train_transform  # Apply transformations\n",
        ")\n",
        "test_dataset = datasets.CIFAR100(\n",
        "    root='./data',       # Change this path if needed\n",
        "    train=False,          # Set to True to download the training set\n",
        "    download=True,       # Set to True to download if not already downloaded\n",
        "    transform=test_transform  # Apply transformations\n",
        ")\n",
        "##### Hyper-parameters\n",
        "\n",
        "\n",
        "# Create a DataLoader for batch processing\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,      # Batch size (you can modify this as needed)\n",
        "    shuffle=True        # Shuffle data for training\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,      # Batch size (you can modify this as needed)\n",
        "    shuffle=False        # Shuffle data for training\n",
        ")\n"
      ],
      "metadata": {
        "id": "dvm1Cjngv7Pr",
        "outputId": "be04722b-8e82-4c6c-ac9b-e07e849cce26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFARClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFARClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout4 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(512*2*2, 256)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu1(x)\n",
        "      x = self.pool1(x)\n",
        "      x = self.dropout1(x)\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.relu2(x)\n",
        "      x = self.pool2(x)\n",
        "      x = self.dropout2(x)\n",
        "\n",
        "      x = self.conv3(x)\n",
        "      x = self.bn3(x)\n",
        "      x = self.relu3(x)\n",
        "      x = self.pool3(x)\n",
        "      x = self.dropout3(x)\n",
        "\n",
        "      x = self.conv4(x)\n",
        "      x = self.bn4(x)\n",
        "      x = self.relu4(x)\n",
        "      x = self.pool4(x)\n",
        "      x = self.dropout4(x)\n",
        "\n",
        "      x = self.conv5(x)\n",
        "      x = self.bn5(x)\n",
        "      x = self.relu5(x)\n",
        "      #x = self.pool5(x)\n",
        "\n",
        "      x = x.view(x.size(0), -1)\n",
        "\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu6(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "BuxC_N-PxIvs"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CIFARClassifier().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # CrossEntropy includes softmax\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)"
      ],
      "metadata": {
        "id": "Xl1e1dj5xMDu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, criterion):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  loss_batches = []\n",
        "\n",
        "  # Switch to evaluation mode and turn off gradient calculation\n",
        "  # since parameters are not updated during testing.\n",
        "  with torch.no_grad():\n",
        "      for images_batch, labels_batch in data_loader:\n",
        "          images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
        "          outputs = model(images_batch) # Forward pass\n",
        "          # The predicted label is the output with the highest activation.\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels_batch.size(0)\n",
        "          correct += (predicted == labels_batch).sum().item()\n",
        "\n",
        "          # Use provided criterion to calculate the loss for the mini batch\n",
        "          # Append the mini-batch loss to loss_batches array\n",
        "          batch_loss = criterion(outputs, labels_batch)\n",
        "          loss_batches.append(batch_loss.item())\n",
        "\n",
        "      accuracy = 100 * correct / total\n",
        "      avg_loss = np.mean(loss_batches)\n",
        "\n",
        "      model.train()\n",
        "\n",
        "\n",
        "      return accuracy, avg_loss"
      ],
      "metadata": {
        "id": "f81I9sMXxPL7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images_batch, labels_batch) in enumerate(train_loader):\n",
        "        optimizer.zero_grad() # Clear the gradients\n",
        "        images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
        "        outputs = model(images_batch) # Forward pass\n",
        "        loss = criterion(outputs, labels_batch) # Calculate loss\n",
        "        loss.backward() # Backward pass\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "    # Evaluate on train and test sets after each epoch\n",
        "\n",
        "    train_accuracy, train_loss = evaluate(model, train_loader, criterion)\n",
        "    test_accuracy, test_loss = evaluate(model, test_loader, criterion)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1:02d}/{num_epochs:02d} - Train Loss: {train_loss:.6f}, Train Acc: {train_accuracy:.2f}%')\n",
        "    print(f'            - Test Loss: {test_loss:.6f}, Test Acc: {test_accuracy:.2f}%')\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)"
      ],
      "metadata": {
        "id": "1UxXh0LmxSnI",
        "outputId": "c73898fb-42fe-4555-afbb-0e3424b7bb73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/100 - Train Loss: 4.096209, Train Acc: 5.60%\n",
            "            - Test Loss: 4.101091, Test Acc: 6.14%\n",
            "------------------------------------------------------------\n",
            "Epoch 02/100 - Train Loss: 3.848285, Train Acc: 9.09%\n",
            "            - Test Loss: 3.856274, Test Acc: 9.61%\n",
            "------------------------------------------------------------\n",
            "Epoch 03/100 - Train Loss: 3.733185, Train Acc: 10.40%\n",
            "            - Test Loss: 3.735750, Test Acc: 10.70%\n",
            "------------------------------------------------------------\n",
            "Epoch 04/100 - Train Loss: 3.606571, Train Acc: 12.98%\n",
            "            - Test Loss: 3.608780, Test Acc: 13.53%\n",
            "------------------------------------------------------------\n",
            "Epoch 05/100 - Train Loss: 3.506551, Train Acc: 14.98%\n",
            "            - Test Loss: 3.498977, Test Acc: 15.56%\n",
            "------------------------------------------------------------\n",
            "Epoch 06/100 - Train Loss: 3.355623, Train Acc: 18.13%\n",
            "            - Test Loss: 3.354712, Test Acc: 17.88%\n",
            "------------------------------------------------------------\n",
            "Epoch 07/100 - Train Loss: 3.182730, Train Acc: 21.48%\n",
            "            - Test Loss: 3.178789, Test Acc: 21.59%\n",
            "------------------------------------------------------------\n",
            "Epoch 08/100 - Train Loss: 3.026801, Train Acc: 24.58%\n",
            "            - Test Loss: 3.018946, Test Acc: 24.52%\n",
            "------------------------------------------------------------\n",
            "Epoch 09/100 - Train Loss: 2.881335, Train Acc: 27.04%\n",
            "            - Test Loss: 2.878101, Test Acc: 27.20%\n",
            "------------------------------------------------------------\n",
            "Epoch 10/100 - Train Loss: 2.832467, Train Acc: 28.20%\n",
            "            - Test Loss: 2.809270, Test Acc: 28.86%\n",
            "------------------------------------------------------------\n",
            "Epoch 11/100 - Train Loss: 2.774848, Train Acc: 29.72%\n",
            "            - Test Loss: 2.756292, Test Acc: 29.89%\n",
            "------------------------------------------------------------\n",
            "Epoch 12/100 - Train Loss: 2.654312, Train Acc: 31.61%\n",
            "            - Test Loss: 2.677496, Test Acc: 31.28%\n",
            "------------------------------------------------------------\n",
            "Epoch 13/100 - Train Loss: 2.561933, Train Acc: 33.74%\n",
            "            - Test Loss: 2.583724, Test Acc: 33.62%\n",
            "------------------------------------------------------------\n",
            "Epoch 14/100 - Train Loss: 2.484836, Train Acc: 35.48%\n",
            "            - Test Loss: 2.506817, Test Acc: 35.37%\n",
            "------------------------------------------------------------\n",
            "Epoch 15/100 - Train Loss: 2.354591, Train Acc: 37.92%\n",
            "            - Test Loss: 2.409384, Test Acc: 37.44%\n",
            "------------------------------------------------------------\n",
            "Epoch 16/100 - Train Loss: 2.357336, Train Acc: 38.59%\n",
            "            - Test Loss: 2.410482, Test Acc: 38.08%\n",
            "------------------------------------------------------------\n",
            "Epoch 17/100 - Train Loss: 2.290229, Train Acc: 39.76%\n",
            "            - Test Loss: 2.355262, Test Acc: 39.08%\n",
            "------------------------------------------------------------\n",
            "Epoch 18/100 - Train Loss: 2.264880, Train Acc: 40.15%\n",
            "            - Test Loss: 2.333829, Test Acc: 39.06%\n",
            "------------------------------------------------------------\n",
            "Epoch 19/100 - Train Loss: 2.234004, Train Acc: 41.09%\n",
            "            - Test Loss: 2.309300, Test Acc: 40.09%\n",
            "------------------------------------------------------------\n",
            "Epoch 20/100 - Train Loss: 2.109062, Train Acc: 43.54%\n",
            "            - Test Loss: 2.203787, Test Acc: 41.82%\n",
            "------------------------------------------------------------\n",
            "Epoch 21/100 - Train Loss: 2.173755, Train Acc: 42.53%\n",
            "            - Test Loss: 2.280833, Test Acc: 40.86%\n",
            "------------------------------------------------------------\n",
            "Epoch 22/100 - Train Loss: 2.081559, Train Acc: 44.53%\n",
            "            - Test Loss: 2.214292, Test Acc: 42.92%\n",
            "------------------------------------------------------------\n",
            "Epoch 23/100 - Train Loss: 2.065749, Train Acc: 44.82%\n",
            "            - Test Loss: 2.192136, Test Acc: 42.52%\n",
            "------------------------------------------------------------\n",
            "Epoch 24/100 - Train Loss: 1.968889, Train Acc: 46.85%\n",
            "            - Test Loss: 2.132676, Test Acc: 44.37%\n",
            "------------------------------------------------------------\n",
            "Epoch 25/100 - Train Loss: 1.943288, Train Acc: 47.66%\n",
            "            - Test Loss: 2.094014, Test Acc: 45.11%\n",
            "------------------------------------------------------------\n",
            "Epoch 26/100 - Train Loss: 1.925355, Train Acc: 47.77%\n",
            "            - Test Loss: 2.112015, Test Acc: 44.65%\n",
            "------------------------------------------------------------\n",
            "Epoch 27/100 - Train Loss: 1.905311, Train Acc: 48.43%\n",
            "            - Test Loss: 2.113665, Test Acc: 45.14%\n",
            "------------------------------------------------------------\n",
            "Epoch 28/100 - Train Loss: 1.872874, Train Acc: 48.93%\n",
            "            - Test Loss: 2.082098, Test Acc: 46.10%\n",
            "------------------------------------------------------------\n",
            "Epoch 29/100 - Train Loss: 1.873705, Train Acc: 49.42%\n",
            "            - Test Loss: 2.085925, Test Acc: 46.29%\n",
            "------------------------------------------------------------\n",
            "Epoch 30/100 - Train Loss: 1.858591, Train Acc: 49.37%\n",
            "            - Test Loss: 2.075050, Test Acc: 45.80%\n",
            "------------------------------------------------------------\n",
            "Epoch 31/100 - Train Loss: 1.784083, Train Acc: 50.95%\n",
            "            - Test Loss: 2.032847, Test Acc: 46.36%\n",
            "------------------------------------------------------------\n",
            "Epoch 32/100 - Train Loss: 1.727629, Train Acc: 52.25%\n",
            "            - Test Loss: 2.011469, Test Acc: 47.54%\n",
            "------------------------------------------------------------\n",
            "Epoch 33/100 - Train Loss: 1.705068, Train Acc: 52.79%\n",
            "            - Test Loss: 1.998466, Test Acc: 47.36%\n",
            "------------------------------------------------------------\n",
            "Epoch 34/100 - Train Loss: 1.729158, Train Acc: 52.31%\n",
            "            - Test Loss: 2.029582, Test Acc: 47.58%\n",
            "------------------------------------------------------------\n",
            "Epoch 35/100 - Train Loss: 1.640930, Train Acc: 54.56%\n",
            "            - Test Loss: 1.965561, Test Acc: 48.54%\n",
            "------------------------------------------------------------\n",
            "Epoch 36/100 - Train Loss: 1.632858, Train Acc: 54.62%\n",
            "            - Test Loss: 1.959550, Test Acc: 48.89%\n",
            "------------------------------------------------------------\n",
            "Epoch 37/100 - Train Loss: 1.613036, Train Acc: 54.94%\n",
            "            - Test Loss: 1.962570, Test Acc: 49.13%\n",
            "------------------------------------------------------------\n",
            "Epoch 38/100 - Train Loss: 1.580048, Train Acc: 55.62%\n",
            "            - Test Loss: 1.940496, Test Acc: 49.56%\n",
            "------------------------------------------------------------\n",
            "Epoch 39/100 - Train Loss: 1.577716, Train Acc: 55.91%\n",
            "            - Test Loss: 1.958247, Test Acc: 49.54%\n",
            "------------------------------------------------------------\n",
            "Epoch 40/100 - Train Loss: 1.565475, Train Acc: 55.92%\n",
            "            - Test Loss: 1.943432, Test Acc: 49.01%\n",
            "------------------------------------------------------------\n",
            "Epoch 41/100 - Train Loss: 1.573258, Train Acc: 56.22%\n",
            "            - Test Loss: 1.951617, Test Acc: 49.21%\n",
            "------------------------------------------------------------\n",
            "Epoch 42/100 - Train Loss: 1.513179, Train Acc: 57.23%\n",
            "            - Test Loss: 1.922993, Test Acc: 49.86%\n",
            "------------------------------------------------------------\n",
            "Epoch 43/100 - Train Loss: 1.541762, Train Acc: 56.63%\n",
            "            - Test Loss: 1.946546, Test Acc: 49.81%\n",
            "------------------------------------------------------------\n",
            "Epoch 44/100 - Train Loss: 1.502431, Train Acc: 57.74%\n",
            "            - Test Loss: 1.921347, Test Acc: 50.23%\n",
            "------------------------------------------------------------\n",
            "Epoch 45/100 - Train Loss: 1.481477, Train Acc: 58.16%\n",
            "            - Test Loss: 1.918442, Test Acc: 50.44%\n",
            "------------------------------------------------------------\n",
            "Epoch 46/100 - Train Loss: 1.466463, Train Acc: 58.66%\n",
            "            - Test Loss: 1.900260, Test Acc: 50.27%\n",
            "------------------------------------------------------------\n",
            "Epoch 47/100 - Train Loss: 1.450878, Train Acc: 59.01%\n",
            "            - Test Loss: 1.924523, Test Acc: 50.32%\n",
            "------------------------------------------------------------\n",
            "Epoch 48/100 - Train Loss: 1.442559, Train Acc: 59.17%\n",
            "            - Test Loss: 1.913583, Test Acc: 50.96%\n",
            "------------------------------------------------------------\n",
            "Epoch 49/100 - Train Loss: 1.428329, Train Acc: 59.48%\n",
            "            - Test Loss: 1.897588, Test Acc: 51.26%\n",
            "------------------------------------------------------------\n",
            "Epoch 50/100 - Train Loss: 1.373171, Train Acc: 60.90%\n",
            "            - Test Loss: 1.885591, Test Acc: 51.89%\n",
            "------------------------------------------------------------\n",
            "Epoch 51/100 - Train Loss: 1.424031, Train Acc: 59.63%\n",
            "            - Test Loss: 1.905538, Test Acc: 50.88%\n",
            "------------------------------------------------------------\n",
            "Epoch 52/100 - Train Loss: 1.367620, Train Acc: 61.05%\n",
            "            - Test Loss: 1.868034, Test Acc: 51.79%\n",
            "------------------------------------------------------------\n",
            "Epoch 53/100 - Train Loss: 1.366742, Train Acc: 60.78%\n",
            "            - Test Loss: 1.885290, Test Acc: 51.28%\n",
            "------------------------------------------------------------\n",
            "Epoch 54/100 - Train Loss: 1.447041, Train Acc: 59.27%\n",
            "            - Test Loss: 1.956165, Test Acc: 50.15%\n",
            "------------------------------------------------------------\n",
            "Epoch 55/100 - Train Loss: 1.363519, Train Acc: 60.99%\n",
            "            - Test Loss: 1.906946, Test Acc: 51.48%\n",
            "------------------------------------------------------------\n",
            "Epoch 56/100 - Train Loss: 1.328593, Train Acc: 61.68%\n",
            "            - Test Loss: 1.855964, Test Acc: 51.92%\n",
            "------------------------------------------------------------\n",
            "Epoch 57/100 - Train Loss: 1.358586, Train Acc: 61.36%\n",
            "            - Test Loss: 1.900812, Test Acc: 51.49%\n",
            "------------------------------------------------------------\n",
            "Epoch 58/100 - Train Loss: 1.296805, Train Acc: 62.62%\n",
            "            - Test Loss: 1.886275, Test Acc: 52.02%\n",
            "------------------------------------------------------------\n",
            "Epoch 59/100 - Train Loss: 1.285180, Train Acc: 62.95%\n",
            "            - Test Loss: 1.889630, Test Acc: 52.27%\n",
            "------------------------------------------------------------\n",
            "Epoch 60/100 - Train Loss: 1.294341, Train Acc: 62.89%\n",
            "            - Test Loss: 1.876091, Test Acc: 52.44%\n",
            "------------------------------------------------------------\n",
            "Epoch 61/100 - Train Loss: 1.274065, Train Acc: 63.35%\n",
            "            - Test Loss: 1.864116, Test Acc: 52.05%\n",
            "------------------------------------------------------------\n",
            "Epoch 62/100 - Train Loss: 1.276876, Train Acc: 63.22%\n",
            "            - Test Loss: 1.885456, Test Acc: 51.48%\n",
            "------------------------------------------------------------\n",
            "Epoch 63/100 - Train Loss: 1.219344, Train Acc: 64.91%\n",
            "            - Test Loss: 1.862418, Test Acc: 52.56%\n",
            "------------------------------------------------------------\n",
            "Epoch 64/100 - Train Loss: 1.195130, Train Acc: 65.43%\n",
            "            - Test Loss: 1.841723, Test Acc: 52.84%\n",
            "------------------------------------------------------------\n",
            "Epoch 65/100 - Train Loss: 1.280535, Train Acc: 63.05%\n",
            "            - Test Loss: 1.889419, Test Acc: 52.18%\n",
            "------------------------------------------------------------\n",
            "Epoch 66/100 - Train Loss: 1.254688, Train Acc: 63.83%\n",
            "            - Test Loss: 1.885956, Test Acc: 52.55%\n",
            "------------------------------------------------------------\n",
            "Epoch 67/100 - Train Loss: 1.277862, Train Acc: 63.43%\n",
            "            - Test Loss: 1.922310, Test Acc: 51.99%\n",
            "------------------------------------------------------------\n",
            "Epoch 68/100 - Train Loss: 1.161502, Train Acc: 66.12%\n",
            "            - Test Loss: 1.841479, Test Acc: 53.42%\n",
            "------------------------------------------------------------\n",
            "Epoch 69/100 - Train Loss: 1.255111, Train Acc: 63.79%\n",
            "            - Test Loss: 1.924093, Test Acc: 51.99%\n",
            "------------------------------------------------------------\n",
            "Epoch 70/100 - Train Loss: 1.188501, Train Acc: 65.83%\n",
            "            - Test Loss: 1.867435, Test Acc: 52.57%\n",
            "------------------------------------------------------------\n",
            "Epoch 71/100 - Train Loss: 1.172455, Train Acc: 66.06%\n",
            "            - Test Loss: 1.857335, Test Acc: 52.62%\n",
            "------------------------------------------------------------\n",
            "Epoch 72/100 - Train Loss: 1.154966, Train Acc: 66.26%\n",
            "            - Test Loss: 1.860847, Test Acc: 52.93%\n",
            "------------------------------------------------------------\n",
            "Epoch 73/100 - Train Loss: 1.184264, Train Acc: 65.70%\n",
            "            - Test Loss: 1.909120, Test Acc: 52.37%\n",
            "------------------------------------------------------------\n",
            "Epoch 74/100 - Train Loss: 1.176877, Train Acc: 65.91%\n",
            "            - Test Loss: 1.880378, Test Acc: 53.03%\n",
            "------------------------------------------------------------\n",
            "Epoch 75/100 - Train Loss: 1.187341, Train Acc: 65.54%\n",
            "            - Test Loss: 1.898075, Test Acc: 52.83%\n",
            "------------------------------------------------------------\n",
            "Epoch 76/100 - Train Loss: 1.129223, Train Acc: 66.98%\n",
            "            - Test Loss: 1.865776, Test Acc: 52.95%\n",
            "------------------------------------------------------------\n",
            "Epoch 77/100 - Train Loss: 1.126933, Train Acc: 67.15%\n",
            "            - Test Loss: 1.858758, Test Acc: 53.29%\n",
            "------------------------------------------------------------\n",
            "Epoch 78/100 - Train Loss: 1.078717, Train Acc: 68.37%\n",
            "            - Test Loss: 1.850283, Test Acc: 53.93%\n",
            "------------------------------------------------------------\n",
            "Epoch 79/100 - Train Loss: 1.152570, Train Acc: 66.47%\n",
            "            - Test Loss: 1.901871, Test Acc: 53.09%\n",
            "------------------------------------------------------------\n",
            "Epoch 80/100 - Train Loss: 1.141434, Train Acc: 66.85%\n",
            "            - Test Loss: 1.911250, Test Acc: 53.07%\n",
            "------------------------------------------------------------\n",
            "Epoch 81/100 - Train Loss: 1.103121, Train Acc: 67.75%\n",
            "            - Test Loss: 1.860728, Test Acc: 53.82%\n",
            "------------------------------------------------------------\n",
            "Epoch 82/100 - Train Loss: 1.131761, Train Acc: 67.06%\n",
            "            - Test Loss: 1.870773, Test Acc: 53.24%\n",
            "------------------------------------------------------------\n",
            "Epoch 83/100 - Train Loss: 1.086532, Train Acc: 68.16%\n",
            "            - Test Loss: 1.863588, Test Acc: 53.58%\n",
            "------------------------------------------------------------\n",
            "Epoch 84/100 - Train Loss: 1.091606, Train Acc: 68.13%\n",
            "            - Test Loss: 1.877645, Test Acc: 53.39%\n",
            "------------------------------------------------------------\n",
            "Epoch 85/100 - Train Loss: 1.096744, Train Acc: 67.84%\n",
            "            - Test Loss: 1.888705, Test Acc: 52.67%\n",
            "------------------------------------------------------------\n",
            "Epoch 86/100 - Train Loss: 1.050776, Train Acc: 68.99%\n",
            "            - Test Loss: 1.831711, Test Acc: 54.10%\n",
            "------------------------------------------------------------\n",
            "Epoch 87/100 - Train Loss: 1.103193, Train Acc: 67.92%\n",
            "            - Test Loss: 1.874997, Test Acc: 52.89%\n",
            "------------------------------------------------------------\n",
            "Epoch 88/100 - Train Loss: 1.130299, Train Acc: 66.98%\n",
            "            - Test Loss: 1.931710, Test Acc: 52.80%\n",
            "------------------------------------------------------------\n",
            "Epoch 89/100 - Train Loss: 1.108797, Train Acc: 67.84%\n",
            "            - Test Loss: 1.894840, Test Acc: 53.14%\n",
            "------------------------------------------------------------\n",
            "Epoch 90/100 - Train Loss: 1.012710, Train Acc: 70.22%\n",
            "            - Test Loss: 1.870436, Test Acc: 54.06%\n",
            "------------------------------------------------------------\n",
            "Epoch 91/100 - Train Loss: 1.003858, Train Acc: 70.21%\n",
            "            - Test Loss: 1.862829, Test Acc: 53.97%\n",
            "------------------------------------------------------------\n",
            "Epoch 92/100 - Train Loss: 1.039850, Train Acc: 69.68%\n",
            "            - Test Loss: 1.837824, Test Acc: 53.77%\n",
            "------------------------------------------------------------\n",
            "Epoch 93/100 - Train Loss: 1.027031, Train Acc: 69.77%\n",
            "            - Test Loss: 1.852270, Test Acc: 53.52%\n",
            "------------------------------------------------------------\n",
            "Epoch 94/100 - Train Loss: 1.031888, Train Acc: 69.74%\n",
            "            - Test Loss: 1.894243, Test Acc: 53.70%\n",
            "------------------------------------------------------------\n",
            "Epoch 95/100 - Train Loss: 0.975626, Train Acc: 70.84%\n",
            "            - Test Loss: 1.868014, Test Acc: 53.90%\n",
            "------------------------------------------------------------\n",
            "Epoch 96/100 - Train Loss: 1.020682, Train Acc: 70.01%\n",
            "            - Test Loss: 1.859290, Test Acc: 53.67%\n",
            "------------------------------------------------------------\n",
            "Epoch 97/100 - Train Loss: 1.017210, Train Acc: 70.19%\n",
            "            - Test Loss: 1.870725, Test Acc: 53.51%\n",
            "------------------------------------------------------------\n",
            "Epoch 98/100 - Train Loss: 0.956349, Train Acc: 71.56%\n",
            "            - Test Loss: 1.847096, Test Acc: 54.35%\n",
            "------------------------------------------------------------\n",
            "Epoch 99/100 - Train Loss: 0.991742, Train Acc: 70.58%\n",
            "            - Test Loss: 1.875432, Test Acc: 53.88%\n",
            "------------------------------------------------------------\n",
            "Epoch 100/100 - Train Loss: 0.998147, Train Acc: 70.62%\n",
            "            - Test Loss: 1.872217, Test Acc: 53.85%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test.csv\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Extract IDs and image data\n",
        "test_ids = test_data[\"ID\"]\n",
        "image_data = test_data.drop(columns=[\"ID\"]).values\n",
        "\n",
        "# Reshape to (num_samples, 3, 32, 32) without normalization\n",
        "num_samples = image_data.shape[0]\n",
        "images = image_data.reshape(num_samples, 3, 32, 32).astype('float32')  # Assuming it's normalized already\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "images_tensor = torch.tensor(images)"
      ],
      "metadata": {
        "id": "3bFwrBjaT9fx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TensorDataset(images_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aqMcmAwtUVnr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images_batch in test_loader:\n",
        "        images_batch = images_batch[0].to(device)  # Move to GPU/CPU\n",
        "        outputs = model(images_batch)  # Forward pass\n",
        "        predicted_labels = torch.argmax(outputs, dim=1)  # Predicted class\n",
        "        predictions.extend(predicted_labels.cpu().numpy())  # Collect predictions"
      ],
      "metadata": {
        "id": "7Yyfv6q7Ut4N"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine predictions with IDs\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"Label\": predictions\n",
        "})\n",
        "\n",
        "# Save predictions to CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "id": "z0zhH3W0UyKI",
        "outputId": "77993cc2-9202-46ad-f851-df5fc50e7b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    }
  ]
}